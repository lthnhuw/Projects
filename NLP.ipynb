{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **I - Mô hình Transformer Cơ bản**"
      ],
      "metadata": {
        "id": "Ys_loN6AffHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 1: Cài đặt môi trường và thư viện**"
      ],
      "metadata": {
        "id": "y5KYzw4bKgPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chạy ô này ĐẦU TIÊN và DUY NHẤT để cài đặt/nâng cấp\n",
        "# Lệnh này sẽ cài đặt PyTorch, Torchvision và các thư viện liên quan với phiên bản tương thích\n",
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Nâng cấp các thư viện cần thiết khác\n",
        "!pip install --upgrade transformers accelerate sentencepiece googletrans sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uwsRqLfG986",
        "outputId": "9567768c-020f-4835-d3d3-069f033ecca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu, transformers, googletrans\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.54.0\n",
            "    Uninstalling transformers-4.54.0:\n",
            "      Successfully uninstalled transformers-4.54.0\n",
            "Successfully installed colorama-0.4.6 googletrans-4.0.2 portalocker-3.2.0 sacrebleu-2.5.1 transformers-4.54.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcuYnCVpClOQ",
        "outputId": "f60538fe-c326-464e-d062-5a2e5ce73f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from googletrans import Translator\n",
        "import sacrebleu\n",
        "from datasets import load_dataset\n",
        "import spacy\n",
        "#from lime.lime_text import LimeTextExplainer\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Kết nối với Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Kiểm tra GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 2: Tải và tiền xử lý dữ liệu**"
      ],
      "metadata": {
        "id": "QAgbqPIEKnZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm đọc và ghép cặp dữ liệu từ Drive\n",
        "def load_split_data_from_drive(en_file, vi_or_th_file, limit=None, drive_path=\"/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/\"):\n",
        "    try:\n",
        "        with open(drive_path + en_file, 'r', encoding='utf-8') as f_en, open(drive_path + vi_or_th_file, 'r', encoding='utf-8') as f_vi_th:\n",
        "            en_lines = f_en.readlines()[:limit] if limit else f_en.readlines()\n",
        "            vi_or_th_lines = f_vi_th.readlines()[:limit] if limit else f_vi_th.readlines()\n",
        "            data = pd.DataFrame({\"en\": en_lines, \"vi\": vi_or_th_lines})\n",
        "            return data\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi đọc file: {e}\")\n",
        "        return None\n",
        "\n",
        "# Đọc PhoMT từ Drive\n",
        "train_phomt = load_split_data_from_drive(\"train_phomt.en\", \"train_phomt.vi\", 120000)\n",
        "val_phomt = load_split_data_from_drive(\"val_phomt.en\", \"val_phomt.vi\", 15000)\n",
        "test_phomt = load_split_data_from_drive(\"test_phomt.en\", \"test_phomt.vi\", 15000)\n",
        "\n",
        "# Đọc dữ liệu Thái từ Drive\n",
        "#train_thai = load_split_data_from_drive(\"train_thai.en\", \"train_thai.th\", 50000)\n",
        "#val_thai = load_split_data_from_drive(\"val_thai.en\", \"val_thai.th\", 5000)\n",
        "#test_thai = load_split_data_from_drive(\"test_thai.en\", \"test_thai.th\", 5000)\n",
        "\n",
        "# Hàm tiền xử lý chung\n",
        "def preprocess_text(text):\n",
        "    return text.strip().lower()\n",
        "\n",
        "train_phomt[\"en\"] = train_phomt[\"en\"].apply(preprocess_text)\n",
        "train_phomt[\"vi\"] = train_phomt[\"vi\"].apply(preprocess_text)\n",
        "val_phomt[\"en\"] = val_phomt[\"en\"].apply(preprocess_text)\n",
        "val_phomt[\"vi\"] = val_phomt[\"vi\"].apply(preprocess_text)\n",
        "test_phomt[\"en\"] = test_phomt[\"en\"].apply(preprocess_text)\n",
        "test_phomt[\"vi\"] = test_phomt[\"vi\"].apply(preprocess_text)\n",
        "\n",
        "# Khởi tạo tokenizer và mô hình\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-vi\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "u65YojmrMq4V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "a753c0a7368d4b548eb79eb3a43a53f5",
            "f5990ced2f044b89b147303a1cf2cdeb",
            "391a5822e38e483aa24cd95bc1eae649",
            "92b860a8ea0849aeadb2f18943530cff",
            "33c7380b97ac41e6886869bcb3061f53",
            "327bc0dadb2248c3869025c5072acfdc",
            "aade950c088f43adbe153000acad8c3e",
            "2c6543c5063d4879a888d300dd0d4091",
            "01ae4bfc26254c9e85fc786f2b2c757a",
            "7cfaa6df1afc401f95b60c0bef8bb13d",
            "a4d3d5ae35c14df689ee96a0c0d7d377",
            "312ac9b01f724b5ebcbc9acd85c5e74d",
            "e3a5f2ee99f740e6bd08c18f01e9af2a",
            "e15786b01f6a4a959dd2735f764947f9",
            "0589da915dc64cd497ea78f782e94113",
            "f81a1f7f61894596a4d92b855050c487",
            "45c69f61c81245e295aca3624f216641",
            "4aa24fbb84b140d09df9e08b30cb324a",
            "3f26f024dfc14c68a9ff8cd7e5cd5aeb",
            "eff0227d61c64062beb4a6647352abd7",
            "85d141584cc141298c1ba8abc1b394e6",
            "4bf5eb8225b9482da2716255b67caed9",
            "9ebfa02adff2432f92c28a8b0e17b3c6",
            "fd43fc5082864f36acb0f771f414ec5f",
            "3debaeafed7a45ffb41206ee7f1b7517",
            "2d84612190ca4b008b5589a0489dcc3c",
            "3e7b3f0f545e4b8e800dceaa8b64875f",
            "71b7169886724836943eebff4a0a816e",
            "6b47d9b6fd2d4a2294e7412840763d89",
            "df25d4be8be64c2b9eb1b569692791ac",
            "ff197db624bf4390a69a66cdb9acfeda",
            "861ec28ebb9a4cf4acc318fb4bfb4484",
            "d340700534614f65a4316989cfe77e03",
            "0638c20c6848444f91db73c89d57e076",
            "a14d303ac4e742d1addc7988ca44de4b",
            "baa3b8f049a245f094c6f663d8a506ec",
            "9b002f409103493ebb6ebd025561d8f6",
            "2da260dc817a424fa93675e34132ddf5",
            "9f268062587242f49c27facca4c53902",
            "8ec7b2a7985244c2952ee9c9f5ffd1e5",
            "190015c3f0a54363bcb0d1a604c95cb3",
            "b3151e90592e472cb6dc39f790fcb071",
            "f473e9c4e3db46d79bf2c24a6f92c378",
            "def6235e5b344687a58aa49bfa407377",
            "5c3968a4d43a422aa2fe98bd4d0c7d5c",
            "0910515432ac413e9ee7031ccc221582",
            "5d0f27a733534b0c8053a31059d9ae03",
            "6c46e0bac0304f5b9b59ad421ad1cdd6",
            "8e0e271670084e3194db0cc9c580d7cf",
            "70715df9916344378010e2cdb5e99760",
            "f8e341af81464b37ac911b5cba7faed0",
            "cffc2b62657d40f698bf786060a7944f",
            "ff535c6581a744b7a74789b83f6646aa",
            "f61fa0bd84004cd4b842c148d2b33b98",
            "a59f9dac7c93470fadf1751066205d2d"
          ]
        },
        "outputId": "8be87967-d959-40ad-b930-3cdeb11122ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a753c0a7368d4b548eb79eb3a43a53f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/809k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "312ac9b01f724b5ebcbc9acd85c5e74d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/756k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ebfa02adff2432f92c28a8b0e17b3c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0638c20c6848444f91db73c89d57e076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c3968a4d43a422aa2fe98bd4d0c7d5c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, source_col=\"en\", target_col=\"vi\", max_length=128):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.source_col = source_col\n",
        "        self.target_col = target_col\n",
        "        self.max_length = max_length\n",
        "        self.source_texts = self.dataframe[self.source_col].tolist()\n",
        "        self.target_texts = self.dataframe[self.target_col].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        source_text = self.source_texts[idx]\n",
        "        target_text = self.target_texts[idx]\n",
        "\n",
        "        # Tokenize on the fly\n",
        "        model_inputs = self.tokenizer(source_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "        with self.tokenizer.as_target_tokenizer():\n",
        "            labels = self.tokenizer(target_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        # Để tương thích với mô hình, labels phải là input_ids\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "        # Squeeze để loại bỏ chiều batch không cần thiết (DataLoader sẽ thêm vào sau)\n",
        "        return {key: val.squeeze() for key, val in model_inputs.items()}"
      ],
      "metadata": {
        "id": "Wfb6Ywpr3Awb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 3: Huấn luyện mô hình Transformer cơ bản**"
      ],
      "metadata": {
        "id": "d5xywIf2P14i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "import os\n",
        "import gc\n",
        "from tqdm import tqdm # Thêm tqdm để có thanh tiến trình đẹp mắt\n",
        "\n",
        "def train_model_fully_optimized(model, train_df, val_df, tokenizer, batch_size=32, epochs=30,\n",
        "                                checkpoint_dir=\"/content/drive/My Drive/TieuLuanNLP/model/basic_en_vi/checkpoints/\",\n",
        "                                accumulation_steps=4):\n",
        "\n",
        "    # --- Thiết lập DataLoader ---\n",
        "    train_dataset = TranslationDataset(train_df, tokenizer)\n",
        "    # num_workers > 0 sẽ bật tính năng tải dữ liệu song song, tăng tốc đáng kể\n",
        "    # pin_memory=True giúp chuyển dữ liệu từ CPU sang GPU nhanh hơn\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # (Tùy chọn) Tạo DataLoader cho validation\n",
        "    # val_dataset = TranslationDataset(val_df, tokenizer)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=batch_size * 2) # Batch size có thể lớn hơn khi validation\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-5) # Có thể thử learning rate khác\n",
        "\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    start_epoch = 0\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print(f\"Tiếp tục từ epoch {start_epoch}\")\n",
        "\n",
        "    # ===== VÒNG LẶP HUẤN LUYỆN TỐI ƯU =====\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Sử dụng tqdm để theo dõi tiến trình\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for step, batch in enumerate(progress_bar):\n",
        "            # DataLoader đã tự động chuyển dữ liệu, chỉ cần đưa lên device\n",
        "            inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs.loss\n",
        "            loss = loss / accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            if (step + 1) % accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Cập nhật thanh tiến trình với giá trị loss\n",
        "            # Nhân lại loss với accumulation_steps để hiển thị đúng\n",
        "            progress_bar.set_postfix({\"loss\": loss.item() * accumulation_steps})\n",
        "            total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "            # Không cần giải phóng bộ nhớ quá thường xuyên khi đã dùng DataLoader\n",
        "            # Chỉ thực hiện nếu vẫn gặp lỗi OOM\n",
        "            if (step + 1) % 100 == 0:\n",
        "              del inputs, outputs, loss\n",
        "              gc.collect()\n",
        "              torch.cuda.empty_cache()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(f\"\\nEpoch {epoch+1} - Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # --- (Đề xuất) Thêm vòng lặp Validation ở đây ---\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': avg_train_loss,\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Đã lưu checkpoint tại epoch {epoch+1}\")\n",
        "\n",
        "        # Giải phóng bộ nhớ cuối mỗi epoch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(\"Huấn luyện hoàn tất!\")\n",
        "    return model\n",
        "def train_model(model, train_data, val_data, batch_size=16, epochs=30, checkpoint_dir=\"/content/drive/My Drive/TieuLuanNLP/model/basic_en_vi/checkpoints/\", accumulation_steps=4):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    # Tạo thư mục checkpoint nếu chưa tồn tại\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Kiểm tra checkpoint hiện có\n",
        "    start_epoch = 0\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print(f\"Tiếp tục từ epoch {start_epoch}\")\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        # Reset optimizer gradients lúc bắt đầu mỗi epoch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i in range(0, len(train_data), batch_size):\n",
        "            batch = train_data.iloc[i:i+batch_size]\n",
        "            if batch[\"en\"].isnull().any() or batch[\"vi\"].isnull().any():\n",
        "                print(f\"Lỗi: Dữ liệu null tại batch {i}\")\n",
        "                continue\n",
        "            inputs = tokenizer(batch[\"en\"].tolist(), padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "            labels = tokenizer(batch[\"vi\"].tolist(), padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
        "            outputs = model(**inputs, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            # --- TỐI ƯU 1: TÍCH LŨY GRADIENT ---\n",
        "            # Chuẩn hóa loss theo số bước tích lũy\n",
        "            loss = loss / accumulation_steps\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Chỉ cập nhật trọng số sau accumulation_steps\n",
        "            # (i // batch_size + 1) là số thứ tự của mini-batch hiện tại\n",
        "            if (i // batch_size + 1) % accumulation_steps == 0:\n",
        "                optimizer.step()      # Cập nhật trọng số mô hình\n",
        "                optimizer.zero_grad() # Reset gradient cho lần tích lũy tiếp theo\n",
        "\n",
        "            total_loss += loss.item() * accumulation_steps # Nhân lại để loss đúng với giá trị gốc\n",
        "            # optimizer.step()\n",
        "            # optimizer.zero_grad()\n",
        "            # total_loss += loss.item()\n",
        "            # --- TỐI ƯU 2: GIẢI PHÓNG BỘ NHỚ ---\n",
        "            # Xóa các tensor không còn dùng đến sau mỗi bước\n",
        "            if (i + 1) % 100 == 0:\n",
        "              del inputs, labels, outputs, loss\n",
        "              print(f\"  Batch {i+1}/{len(train_data)}, Loss: {loss.item() * accumulation_steps:.4f}\")\n",
        "              torch.cuda.empty_cache()\n",
        "              gc.collect()\n",
        "\n",
        "\n",
        "        # Tính toán và in loss trung bình cho epoch\n",
        "        # Lưu ý: total_loss đã được nhân lại với accumulation_steps ở trên\n",
        "        avg_train_loss = total_loss / (len(train_data) / batch_size)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {avg_train_loss}\")\n",
        "\n",
        "        # Lưu checkpoint sau mỗi epoch\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': total_loss,\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Đã lưu checkpoint tại epoch {epoch+1}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "model_basic = MarianMTModel.from_pretrained(model_name, weights_only=False).to(device)\n",
        "model_basic = train_model_fully_optimized(model_basic, train_phomt, val_phomt, tokenizer)\n",
        "model_basic.save_pretrained(\"/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/model_basic\")"
      ],
      "metadata": {
        "id": "wV3X_CSndkqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296,
          "referenced_widgets": [
            "31505f30071f4321b5e80922fdfdb390",
            "e678d3e92e4a4c429f9dae2b2c3fa2b3",
            "e28c7acbc7d84025a057804b829855bd",
            "2662517900ac43a9a4fbf77d23f42076",
            "e7b2a4f8266e45abb63067d9e40e9437",
            "4af732e2f00b42888d9092e046df7959",
            "81eb5dc719d24810ab3d11093d8ce572",
            "6e490368ab3c4206a6a47a041102a1ba",
            "1592158a7ece4dafb087a5a21ec38989",
            "f6a372e3692a4282bc3906603d957e09",
            "8fc2567f99524600acc358e5b65c9485",
            "b1b7f7b26dff4b8db2973f24bd51b222",
            "7e43fc5073da41a68ca071ac9c5f7533",
            "0b3b7c6655324f0c99d6d509f044d75b",
            "7e43cf5feb60410b9131e3f543188285",
            "3dcc5a0193b94987af917b29ecc35125",
            "50a59bf2cd7f432fbcfd890e08164ccf",
            "c3713fe13a964827acffea08ddc821d6",
            "f48fa6dcbf324d9aa9585c6ed2143ff2",
            "f7851d30bf164807bf5dd75627465b1f",
            "8aa1062cd1c44211973a82cb155c4a78",
            "99594d0670cf40a485ab0e1db7fa2f0a",
            "d9fd3119203c4224aabfddeec6ff21a0",
            "a9150a14d87549819e29c761b2ce566b",
            "3dadfb815f444d4aba180ef47dff158f",
            "92ec8abf07b549bca3e1b250bec5000e",
            "c26736f543db4bcebaadac33a37da98b",
            "6c6b355d1c0a4d5290c860436fc88d67",
            "d6bd7326d0984fc7b7846807969bace4",
            "47fbc871b46949faafeab2f73000b375",
            "299dba0e356744bfbafc204efb2670d7",
            "70df06ec18034830a991fb27545e764e",
            "40bcc5e403fb4ceaa86162090a4d24a0"
          ]
        },
        "outputId": "3ce3f1a3-c95a-4fca-bfe5-1fa52a844b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/289M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31505f30071f4321b5e80922fdfdb390"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1b7f7b26dff4b8db2973f24bd51b222"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/289M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9fd3119203c4224aabfddeec6ff21a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiếp tục từ epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 3750/3750 [37:55<00:00,  1.65it/s, loss=0.134]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 29 - Average Training Loss: 0.1009\n",
            "Đã lưu checkpoint tại epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 3750/3750 [37:57<00:00,  1.65it/s, loss=0.109]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 30 - Average Training Loss: 0.0962\n",
            "Đã lưu checkpoint tại epoch 30\n",
            "Huấn luyện hoàn tất!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 4: Lưu trữ và sử dụng mô hình Transformer cơ bản**"
      ],
      "metadata": {
        "id": "SetxMZPNP-Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo mô hình# Khởi tạo tokenizer và mô hình\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-vi\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "#model_basic = MarianMTModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "# Huấn luyện\n",
        "#model_basic = train_model(model_basic, train_phomt, val_phomt)\n",
        "\n",
        "#model_basic.save_pretrained(\"/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/model_basic\")\n",
        "\n",
        "#Test model\n",
        "model_basic =  MarianMTModel.from_pretrained(\"/content/drive/My Drive/TieuLuanNLP/model/basic_en_vi/checkpoints/\")\n",
        "\n",
        "sample_english = [\n",
        "        \"Brother Albert Barnett and his wife , Sister Susan Barnett , from the West Congregation in Tuscaloosa , Alabama\",\n",
        "        \"Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12 , 2020 .\",\n",
        "        \"Two days of heavy rain , high winds , and numerous tornadoes caused major damage across multiple states .\",\n",
        "        \"Sadly , Brother Albert Barnett and his wife , Sister Susan Barnett , 85 and 75 years old respectively , were killed when a tornado struck their mobile home .\",\n",
        "        \"The United States branch also reports that at least four of our brothers' homes sustained minor damage , along with two Kingdom Halls .\",\n",
        "        \"Additionally , the storms caused major damage to a brother 's business property .\",\n",
        "        \"Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster .\",\n",
        "        \"We know that our heavenly Father , Jehovah , is providing comfort to our brothers and sisters who are grieving because of this tragedy .\",\n",
        "        \"International government agencies and officials have responded to Russia 's Supreme Court decision that criminalizes the worship of Jehovah 's Witnesses in Russia .\",\n",
        "        \"These statements have criticized Russia 's unjust and harsh judicial action against a minority religious group known for peaceful religious activity .\"\n",
        "    ]\n",
        "print(\" BẮT ĐẦU KIỂM TRA MÔ HÌNH VỚI 10 CÂU VÍ DỤ \".center(80, \"=\"))\n",
        "\n",
        "# 2. Dịch từng câu và in kết quả\n",
        "for i in range(len(sample_english)):\n",
        "  text = sample_english[i]\n",
        "\n",
        "  # Chuẩn bị input\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)  # Đảm bảo input trên CPU\n",
        "  print(f\"\\n--- CÂU {i+1} ---\")\n",
        "  print(f\"  > Tiếng Anh:\".ljust(25), f\"{text}\")\n",
        "  # Dự đoán\n",
        "  outputs = model_basic.generate(**inputs)\n",
        "  translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  print(\"Translated text:\", translated_text)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"✅ Hoàn tất kiểm tra.\")"
      ],
      "metadata": {
        "id": "E3Epmrdogieg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54749eab-62a0-4d37-b7c6-a02113d72525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================== BẮT ĐẦU KIỂM TRA MÔ HÌNH VỚI 10 CÂU VÍ DỤ ===================\n",
            "\n",
            "--- CÂU 1 ---\n",
            "  > Tiếng Anh:            Brother Albert Barnett and his wife , Sister Susan Barnett , from the West Congregation in Tuscaloosa , Alabama\n",
            "Translated text: Anh Albert Barnett và vợ Susan Barnett từ hội chính phương Tây ở Tuscaloosa, Alabama\n",
            "\n",
            "--- CÂU 2 ---\n",
            "  > Tiếng Anh:            Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12 , 2020 .\n",
            "Translated text: Những cơn khó khăn xảy ra xuyên qua những phần của miền Nam và giữa Tây Nam Mỹ và ngày 11 / 1, 2020.\n",
            "\n",
            "--- CÂU 3 ---\n",
            "  > Tiếng Anh:            Two days of heavy rain , high winds , and numerous tornadoes caused major damage across multiple states .\n",
            "Translated text: Hai ngày có mưa, gió cao, và nhiều cơn lốc xoáy gây ra thiệt hại lớn ở nhiều bang.\n",
            "\n",
            "--- CÂU 4 ---\n",
            "  > Tiếng Anh:            Sadly , Brother Albert Barnett and his wife , Sister Susan Barnett , 85 and 75 years old respectively , were killed when a tornado struck their mobile home .\n",
            "Translated text: Đáng buồn thay, Albert Barnett và vợ ông, Chị Susan Barnett, 85 và 75 tuổi, bị giết khi có cơn lốc xoáy vào ngôi nhà di động của họ.\n",
            "\n",
            "--- CÂU 5 ---\n",
            "  > Tiếng Anh:            The United States branch also reports that at least four of our brothers' homes sustained minor damage , along with two Kingdom Halls .\n",
            "Translated text: Các công ty Mỹ cũng báo cáo rằng ít nhất bốn gia đình của anh em chúng ta phải chịu tổn thương nhỏ cùng với hai toà nhà nước.\n",
            "\n",
            "--- CÂU 6 ---\n",
            "  > Tiếng Anh:            Additionally , the storms caused major damage to a brother 's business property .\n",
            "Translated text: Thêm nữa, những cơn khó khăn gây ra những thiệt hại lớn cho tài sản của anh trai.\n",
            "\n",
            "--- CÂU 7 ---\n",
            "  > Tiếng Anh:            Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster .\n",
            "Translated text: Các thanh niên địa phương và chăm sát điện tử đang hỗ trợ thực tế và tinh thần cho những người bị ảnh hưởng bởi thảm hoạ này.\n",
            "\n",
            "--- CÂU 8 ---\n",
            "  > Tiếng Anh:            We know that our heavenly Father , Jehovah , is providing comfort to our brothers and sisters who are grieving because of this tragedy .\n",
            "Translated text: Chúng ta biết rằng Cha trên trời, Jehovah, đang mang đến sự an ủi cho anh chị em mình, những người đang đau khổ vì bi kịch này.\n",
            "\n",
            "--- CÂU 9 ---\n",
            "  > Tiếng Anh:            International government agencies and officials have responded to Russia 's Supreme Court decision that criminalizes the worship of Jehovah 's Witnesses in Russia .\n",
            "Translated text: Các cơ quan chính phủ quốc tế và các quan chức đã phản ứng lại với quyết định Toà án tối cao của Nga là buộc tội sự tôn thờ của chính phủ Jehovah ở Nga.\n",
            "\n",
            "--- CÂU 10 ---\n",
            "  > Tiếng Anh:            These statements have criticized Russia 's unjust and harsh judicial action against a minority religious group known for peaceful religious activity .\n",
            "Translated text: Những tuyên bố này đã chỉ trích những hành động pháp luận và không công bằng với một nhóm tôn giáo thiếu số được biết đến vì những hoạt động tôn giáo yên bình.\n",
            "================================================================================\n",
            "✅ Hoàn tất kiểm tra.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **II - Mô hình Đa nguồn**"
      ],
      "metadata": {
        "id": "irc7fvxKIeeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cài đặt các phiên bản thư viện cụ thể để đảm bảo tương thích\n",
        "print(\"⚙️ Đang cài đặt các phiên bản thư viện ổn định...\")\n",
        "# Đóng băng phiên bản Numpy ở mức an toàn, tương thích với hầu hết các thư viện\n",
        "!pip install numpy==1.26.4 --quiet\n",
        "# Đóng băng phiên bản torch và torchtext\n",
        "!pip install torch==2.2.0 torchtext==0.17.0 --quiet\n",
        "# Đóng băng phiên bản spacy\n",
        "!pip install spacy==3.7.2 --quiet\n",
        "# Cài đặt các thư viện phụ trợ\n",
        "!pip install portalocker sacrebleu pythainlp underthesea --quiet\n",
        "\n",
        "# 2. Tải mô hình ngôn ngữ cho tiếng Anh (tương thích với spacy 3.7.2)\n",
        "print(\"⚙️ Đang tải mô hình ngôn ngữ cho tiếng Anh...\")\n",
        "!python -m spacy download en_core_web_sm --quiet\n",
        "\n",
        "print(\"✅ Cài đặt và tải mô hình hoàn tất!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# QUAN TRỌNG NHẤT: BẠN PHẢI KHỞI ĐỘNG LẠI RUNTIME SAU KHI CHẠY XONG CELL NÀY\n",
        "# MENU \"Runtime\" -> \"Restart runtime\".\n",
        "# VIỆC NÀY SẼ NẠP CÁC PHIÊN BẢN THƯ VIỆN CHÍNH XÁC MÀ CHÚNG TA VỪA CÀI.\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "FB0SqoDgBSIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5c68b7-b395-458b-b0d8-021b37e75e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Đang cài đặt các phiên bản thư viện ổn định...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.38.2 requires typer<1.0,>=0.12; sys_platform != \"emscripten\", but you have typer 0.9.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h⚙️ Đang tải mô hình ngôn ngữ cho tiếng Anh...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "✅ Cài đặt và tải mô hình hoàn tất!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Import các thư viện\n",
        "import numpy\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "from google.colab import drive\n",
        "import sacrebleu\n",
        "from pythainlp.tokenize import word_tokenize as th_word_tokenize\n",
        "from underthesea import word_tokenize as vi_word_tokenize\n",
        "\n",
        "print(\"✅ Import thư viện hoàn tất!\")\n",
        "print(f\"Phiên bản Numpy đang dùng: {numpy.__version__}\")\n",
        "print(f\"Phiên bản Torch đang dùng: {torch.__version__}\")\n",
        "\n",
        "\n",
        "# 4. Thiết lập Tokenizer và Vocab (Phần này giữ nguyên)\n",
        "\n",
        "# Kết nối Google Drive và lấy đường dẫn file\n",
        "drive.mount('/content/drive')\n",
        "EN_FILE_PATH = '/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/train_thai.en'\n",
        "TH_FILE_PATH = '/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/train_thai.th'\n",
        "VI_FILE_PATH = '/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/train_thai.vi'\n",
        "\n",
        "print(\"⚙️ Đang thiết lập tokenizer...\")\n",
        "nlp_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in nlp_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_th(text):\n",
        "    return th_word_tokenize(text)\n",
        "\n",
        "def tokenize_vi(text):\n",
        "    return vi_word_tokenize(text)\n",
        "\n",
        "print(\"✅ Tokenizer sẵn sàng!\")\n",
        "\n",
        "def build_vocabulary(filepath, tokenizer, specials=['<unk>', '<pad>', '<bos>', '<eos>']):\n",
        "    def yield_tokens(filepath, tokenizer):\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                yield tokenizer(line.strip())\n",
        "\n",
        "    vocab = build_vocab_from_iterator(yield_tokens(filepath, tokenizer), specials=specials)\n",
        "    vocab.set_default_index(vocab['<unk>'])\n",
        "    return vocab\n",
        "\n",
        "print(\"⚙️ Đang xây dựng vocab...\")\n",
        "vocab_en = build_vocabulary(EN_FILE_PATH, tokenize_en)\n",
        "vocab_th = build_vocabulary(TH_FILE_PATH, tokenize_th)\n",
        "vocab_vi = build_vocabulary(VI_FILE_PATH, tokenize_vi)\n",
        "\n",
        "print(f\"Kích thước Vocab Anh: {len(vocab_en)}\")\n",
        "print(f\"Kích thước Vocab Thái: {len(vocab_th)}\")\n",
        "print(f\"Kích thước Vocab Việt: {len(vocab_vi)}\")\n",
        "\n",
        "# class TranslationDataset(Dataset):\n",
        "#     def __init__(self, en_path, th_path, vi_path):\n",
        "#         with open(en_path, 'r', encoding='utf-8') as f:\n",
        "#             self.en_data = f.readlines()\n",
        "#         with open(th_path, 'r', encoding='utf-8') as f:\n",
        "#             self.th_data = f.readlines()\n",
        "#         with open(vi_path, 'r', encoding='utf-8') as f:\n",
        "#             self.vi_data = f.readlines()\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.vi_data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.en_data[idx].strip(), self.th_data[idx].strip(), self.vi_data[idx].strip()\n",
        "# Phiên bản TranslationDataset linh hoạt hơn\n",
        "class TranslationDataset(Dataset):\n",
        "    # Thay đổi tên tham số để trở nên tổng quát\n",
        "    def __init__(self, src1_path, src2_path, tgt_path):\n",
        "        with open(src1_path, 'r', encoding='utf-8') as f:\n",
        "            self.src1_data = f.readlines()\n",
        "        with open(src2_path, 'r', encoding='utf-8') as f:\n",
        "            self.src2_data = f.readlines()\n",
        "        with open(tgt_path, 'r', encoding='utf-8') as f:\n",
        "            self.tgt_data = f.readlines()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Dùng độ dài của file đích làm tham chiếu\n",
        "        return len(self.tgt_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Trả về theo đúng thứ tự tổng quát\n",
        "        return self.src1_data[idx].strip(), self.src2_data[idx].strip(), self.tgt_data[idx].strip()\n",
        "\n",
        "PAD_IDX = vocab_en['<pad>']\n",
        "BOS_IDX = vocab_en['<bos>']\n",
        "EOS_IDX = vocab_en['<eos>']\n",
        "\n",
        "# def collate_fn(batch):\n",
        "#    en_batch, th_batch, vi_batch = [], [], []\n",
        "#    for en_text, th_text, vi_text in batch:\n",
        "#         en_tensor = torch.tensor([BOS_IDX] + [vocab_en[token] for token in tokenize_en(en_text)] + [EOS_IDX])\n",
        "#         th_tensor = torch.tensor([BOS_IDX] + [vocab_th[token] for token in tokenize_th(th_text)] + [EOS_IDX])\n",
        "#         vi_tensor = torch.tensor([BOS_IDX] + [vocab_vi[token] for token in tokenize_vi(vi_text)] + [EOS_IDX])\n",
        "#         en_batch.append(en_tensor)\n",
        "#         th_batch.append(th_tensor)\n",
        "#         vi_batch.append(vi_tensor)\n",
        "\n",
        "#     en_padded = pad_sequence(en_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "#     th_padded = pad_sequence(th_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "#     max_len = max(en_padded.size(1), th_padded.size(1))\n",
        "\n",
        "#     if en_padded.size(1) < max_len:\n",
        "#         pad_needed = max_len - en_padded.size(1)\n",
        "#         en_padded = F.pad(en_padded, (0, pad_needed), 'constant', PAD_IDX)\n",
        "#     if th_padded.size(1) < max_len:\n",
        "#         pad_needed = max_len - th_padded.size(1)\n",
        "#         th_padded = F.pad(th_padded, (0, pad_needed), 'constant', PAD_IDX)\n",
        "\n",
        "#     vi_padded = pad_sequence(vi_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "#     return en_padded, th_padded, vi_padded\n",
        "\n",
        "def collate_fn(batch):\n",
        "    vi_batch, th_batch, en_batch = [], [], []\n",
        "\n",
        "    # Thay đổi thứ tự đọc dữ liệu: (vi_text, th_text) là nguồn, (en_text) là đích\n",
        "    for vi_text, th_text, en_text in batch:\n",
        "        vi_tensor = torch.tensor([BOS_IDX] + [vocab_vi[token] for token in tokenize_vi(vi_text)] + [EOS_IDX])\n",
        "        th_tensor = torch.tensor([BOS_IDX] + [vocab_th[token] for token in tokenize_th(th_text)] + [EOS_IDX])\n",
        "        en_tensor = torch.tensor([BOS_IDX] + [vocab_en[token] for token in tokenize_en(en_text)] + [EOS_IDX])\n",
        "        vi_batch.append(vi_tensor)\n",
        "        th_batch.append(th_tensor)\n",
        "        en_batch.append(en_tensor)\n",
        "\n",
        "    # Padding đồng bộ cho hai ngôn ngữ nguồn mới (Việt, Thái)\n",
        "    vi_padded = pad_sequence(vi_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "    th_padded = pad_sequence(th_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "    max_src_len = max(vi_padded.size(1), th_padded.size(1))\n",
        "\n",
        "    if vi_padded.size(1) < max_src_len:\n",
        "        vi_padded = F.pad(vi_padded, (0, max_src_len - vi_padded.size(1)), 'constant', PAD_IDX)\n",
        "    if th_padded.size(1) < max_src_len:\n",
        "        th_padded = F.pad(th_padded, (0, max_src_len - th_padded.size(1)), 'constant', PAD_IDX)\n",
        "\n",
        "    # Pad ngôn ngữ đích (Anh) một cách độc lập\n",
        "    en_padded = pad_sequence(en_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "    return vi_padded, th_padded, en_padded\n",
        "\n",
        "print(\"✅ Class Dataset và hàm collate đã được cập nhật!\")"
      ],
      "metadata": {
        "id": "GL0ji6M-Ihxi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "cd75a57a-fe11-494f-c259-55e23e792f08",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-910255321.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3. Import các thư viện\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# set library-specific custom warning handling before doing anything else\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/errors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mcatalogue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_importlib_metadata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimportlib_metadata\u001b[0m  \u001b[0;31m# type: ignore[no-redef]    # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizer\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .backends import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mCupyOps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mMPSOps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mNumpyOps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mOps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/thinc/backends/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_cupy_allocators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcupy_pytorch_allocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcupy_tensorflow_allocator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_server\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParamServer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcupy_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCupyOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmps_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPSOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumpyOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/thinc/backends/cupy_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_custom_kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumpyOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/thinc/backends/numpy_ops.pyx\u001b[0m in \u001b[0;36minit thinc.backends.numpy_ops\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "# Kết nối với Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- THAY ĐỔI CÁC ĐƯỜNG DẪN NÀY CHO PHÙ HỢP ---\n",
        "# Đường dẫn tới các file dữ liệu\n",
        "EN_FILE_PATH = '/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/train_thai.en'\n",
        "TH_FILE_PATH = '/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/train_thai.th'\n",
        "VI_FILE_PATH = '/content/drive/My Drive/TieuLuanNLP/MT_Translation_Data/train_thai.vi'\n",
        "\n",
        "# Đường dẫn để lưu checkpoint\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en'\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "    os.makedirs(CHECKPOINT_DIR)\n",
        "\n",
        "print(\"✅ Kết nối Google Drive và thiết lập đường dẫn hoàn tất!\")\n",
        "print(f\"Thư mục lưu checkpoint: {CHECKPOINT_DIR}\")\n"
      ],
      "metadata": {
        "id": "aPHH-qX1IuNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bb2295-d50f-44af-f769-e182b523f142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Kết nối Google Drive và thiết lập đường dẫn hoàn tất!\n",
            "Thư mục lưu checkpoint: /content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        #====== SỬA LỖI TẠI ĐÂY ======\n",
        "        # Đảm bảo max_len là kiểu int trước khi truyền vào torch.zeros\n",
        "        pe = torch.zeros(int(max_len), d_model)\n",
        "        #============================\n",
        "\n",
        "        position = torch.arange(0, int(max_len), dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class MultiSourceTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers, num_decoder_layers, d_model, num_heads,\n",
        "                 input_vocab_size_en, input_vocab_size_th, output_vocab_size_vi,\n",
        "                 d_ff, dropout=0.1):\n",
        "        super(MultiSourceTransformer, self).__init__()\n",
        "\n",
        "        # --- Encoders ---\n",
        "        self.embedding_en = nn.Embedding(input_vocab_size_en, d_model)\n",
        "        self.embedding_th = nn.Embedding(input_vocab_size_th, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, d_ff, dropout, batch_first=True)\n",
        "        self.transformer_encoder_en = nn.TransformerEncoder(encoder_layer, num_encoder_layers)\n",
        "        self.transformer_encoder_th = nn.TransformerEncoder(encoder_layer, num_encoder_layers)\n",
        "\n",
        "        # --- Decoder ---\n",
        "        self.embedding_vi = nn.Embedding(output_vocab_size_vi, d_model)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, d_ff, dropout, batch_first=True)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers)\n",
        "\n",
        "        # --- Lớp kết hợp 2 encoder output ---\n",
        "        self.fusion_layer = nn.Linear(d_model * 2, d_model)\n",
        "\n",
        "        # --- Lớp đầu ra ---\n",
        "        self.fc_out = nn.Linear(d_model, output_vocab_size_vi)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def create_padding_mask(self, seq, pad_idx):\n",
        "        return (seq == pad_idx)\n",
        "\n",
        "    def forward(self, src_en, src_th, tgt):\n",
        "        # Tạo mask\n",
        "        src_en_padding_mask = self.create_padding_mask(src_en, PAD_IDX).to(device)\n",
        "        src_th_padding_mask = self.create_padding_mask(src_th, PAD_IDX).to(device)\n",
        "        tgt_padding_mask = self.create_padding_mask(tgt, PAD_IDX).to(device)\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
        "\n",
        "        # --- Encoder Forward ---\n",
        "        # Encoder cho tiếng Anh\n",
        "        src_en_emb = self.pos_encoder(self.embedding_en(src_en) * math.sqrt(self.d_model))\n",
        "        memory_en = self.transformer_encoder_en(src_en_emb, src_key_padding_mask=src_en_padding_mask)\n",
        "\n",
        "        # Encoder cho tiếng Thái\n",
        "        src_th_emb = self.pos_encoder(self.embedding_th(src_th) * math.sqrt(self.d_model))\n",
        "        memory_th = self.transformer_encoder_th(src_th_emb, src_key_padding_mask=src_th_padding_mask)\n",
        "\n",
        "        # --- Kết hợp (Fusion) ---\n",
        "        memory_combined = torch.cat((memory_en, memory_th), dim=-1)\n",
        "        memory = torch.tanh(self.fusion_layer(memory_combined))\n",
        "\n",
        "        # --- Decoder Forward ---\n",
        "        tgt_emb = self.pos_encoder(self.embedding_vi(tgt) * math.sqrt(self.d_model))\n",
        "        memory_padding_mask = src_en_padding_mask\n",
        "\n",
        "        output = self.transformer_decoder(tgt_emb, memory,\n",
        "                                          tgt_mask=tgt_mask,\n",
        "                                          tgt_key_padding_mask=tgt_padding_mask,\n",
        "                                          memory_key_padding_mask=memory_padding_mask)\n",
        "\n",
        "        return self.fc_out(output)\n",
        "# class MultiSourceTransformer(nn.Module):\n",
        "#     # Thay đổi tên tham số để trở nên tổng quát\n",
        "#     def __init__(self, num_encoder_layers, num_decoder_layers, d_model, num_heads,\n",
        "#                  input_vocab_size_src1, input_vocab_size_src2, output_vocab_size_tgt,\n",
        "#                  d_ff, dropout=0.1):\n",
        "#         super(MultiSourceTransformer, self).__init__()\n",
        "\n",
        "#         # --- Encoders cho 2 ngôn ngữ nguồn ---\n",
        "#         self.embedding_src1 = nn.Embedding(input_vocab_size_src1, d_model)\n",
        "#         self.embedding_src2 = nn.Embedding(input_vocab_size_src2, d_model)\n",
        "#         self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "#         encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, d_ff, dropout, batch_first=True)\n",
        "#         self.transformer_encoder_src1 = nn.TransformerEncoder(encoder_layer, num_encoder_layers)\n",
        "#         self.transformer_encoder_src2 = nn.TransformerEncoder(encoder_layer, num_encoder_layers)\n",
        "\n",
        "#         # --- Decoder cho ngôn ngữ đích ---\n",
        "#         self.embedding_tgt = nn.Embedding(output_vocab_size_tgt, d_model)\n",
        "#         decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, d_ff, dropout, batch_first=True)\n",
        "#         self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers)\n",
        "\n",
        "#         self.fusion_layer = nn.Linear(d_model * 2, d_model)\n",
        "#         self.fc_out = nn.Linear(d_model, output_vocab_size_tgt)\n",
        "#         self.d_model = d_model\n",
        "\n",
        "#     def generate_square_subsequent_mask(self, sz):\n",
        "#         mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "#         mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "#         return mask\n",
        "\n",
        "#     def create_padding_mask(self, seq, pad_idx):\n",
        "#         return (seq == pad_idx)\n",
        "\n",
        "#     # Thay đổi tên tham số của hàm forward\n",
        "#     def forward(self, src1, src2, tgt):\n",
        "#         # Tạo mask\n",
        "#         src1_padding_mask = self.create_padding_mask(src1, PAD_IDX).to(device)\n",
        "#         src2_padding_mask = self.create_padding_mask(src2, PAD_IDX).to(device)\n",
        "#         tgt_padding_mask = self.create_padding_mask(tgt, PAD_IDX).to(device)\n",
        "#         tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
        "\n",
        "#         # --- Encoder Forward ---\n",
        "#         src1_emb = self.pos_encoder(self.embedding_src1(src1) * math.sqrt(self.d_model))\n",
        "#         memory1 = self.transformer_encoder_src1(src1_emb, src_key_padding_mask=src1_padding_mask)\n",
        "\n",
        "#         src2_emb = self.pos_encoder(self.embedding_src2(src2) * math.sqrt(self.d_model))\n",
        "#         memory2 = self.transformer_encoder_src2(src2_emb, src_key_padding_mask=src2_padding_mask)\n",
        "\n",
        "#         # --- Kết hợp (Fusion) ---\n",
        "#         memory_combined = torch.cat((memory1, memory2), dim=-1)\n",
        "#         memory = torch.tanh(self.fusion_layer(memory_combined))\n",
        "\n",
        "#         # --- Decoder Forward ---\n",
        "#         tgt_emb = self.pos_encoder(self.embedding_tgt(tgt) * math.sqrt(self.d_model))\n",
        "#         memory_padding_mask = src1_padding_mask # Có thể dùng mask của src1 hoặc src2\n",
        "\n",
        "#         output = self.transformer_decoder(tgt_emb, memory,\n",
        "#                                           tgt_mask=tgt_mask,\n",
        "#                                           tgt_key_padding_mask=tgt_padding_mask,\n",
        "#                                           memory_key_padding_mask=memory_padding_mask)\n",
        "\n",
        "#         return self.fc_out(output)\n",
        "\n",
        "print(\"✅ Định nghĩa kiến trúc mô hình hoàn tất!\")"
      ],
      "metadata": {
        "id": "cx9zrRGLJnqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38dae086-2bf9-4ae5-a728-5badb6f4fe0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Định nghĩa kiến trúc mô hình hoàn tất!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Thiết lập các tham số\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Sử dụng thiết bị: {device}\")\n",
        "\n",
        "# --- Các tham số có thể điều chỉnh ---\n",
        "D_MODEL = 512       # Kích thước embedding\n",
        "NUM_HEADS = 8       # Số lượng attention heads\n",
        "NUM_ENCODER_LAYERS = 6\n",
        "NUM_DECODER_LAYERS = 6\n",
        "D_FF = 2048         # Kích thước lớp FeedForward\n",
        "DROPOUT = 0.1\n",
        "BATCH_SIZE = 16     # Giảm batch size để tiết kiệm bộ nhớ, sẽ bù lại bằng Gradient Accumulation\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 30\n",
        "\n",
        "# --- THAM SỐ TỐI ƯU MỚI ---\n",
        "# Tích lũy gradient sau 4 bước. Batch size hiệu quả = 16 * 4 = 64\n",
        "GRADIENT_ACCUMULATION_STEPS = 4\n",
        "# Giảm LR đi 10% sau mỗi 2 epoch\n",
        "LR_SCHEDULER_STEP_SIZE = 2\n",
        "LR_SCHEDULER_GAMMA = 0.9\n",
        "\n",
        "# Khởi tạo mô hình\n",
        "# INPUT_VOCAB_SIZE_EN = len(vocab_en)\n",
        "# INPUT_VOCAB_SIZE_TH = len(vocab_th)\n",
        "# OUTPUT_VOCAB_SIZE_VI = len(vocab_vi)\n",
        "INPUT_VOCAB_SIZE_SRC1 = len(vocab_vi) # Nguồn 1: Tiếng Việt\n",
        "INPUT_VOCAB_SIZE_SRC2 = len(vocab_th) # Nguồn 2: Tiếng Thái\n",
        "OUTPUT_VOCAB_SIZE_TGT = len(vocab_en) # Đích: Tiếng Anh\n",
        "\n",
        "# model = MultiSourceTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, D_MODEL, NUM_HEADS,\n",
        "#                              INPUT_VOCAB_SIZE_EN, INPUT_VOCAB_SIZE_TH, OUTPUT_VOCAB_SIZE_VI,\n",
        "#                              D_FF, DROPOUT).to(device)\n",
        "model = MultiSourceTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, D_MODEL, NUM_HEADS,\n",
        "                             INPUT_VOCAB_SIZE_SRC1, INPUT_VOCAB_SIZE_SRC2, OUTPUT_VOCAB_SIZE_TGT,\n",
        "                             D_FF, DROPOUT).to(device)\n",
        "\n",
        "# Sử dụng AdamW thay cho Adam\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "# Khởi tạo GradScaler cho Mixed Precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Khởi tạo Learning Rate Scheduler\n",
        "scheduler = StepLR(optimizer, step_size=LR_SCHEDULER_STEP_SIZE, gamma=LR_SCHEDULER_GAMMA)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Mô hình có {count_parameters(model):,} tham số có thể huấn luyện.\")\n",
        "print(f\"Batch size thực tế: {BATCH_SIZE}\")\n",
        "print(f\"Các bước tích lũy Gradient: {GRADIENT_ACCUMULATION_STEPS}\")\n",
        "print(f\"Batch size hiệu quả (tương đương): {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
        "print(\"✅ Khởi tạo mô hình và các thành phần tối ưu hoàn tất!\")"
      ],
      "metadata": {
        "id": "E56HNShIKiNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "4511550d-5883-4054-ea1f-467b2d774c92",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vocab_vi' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3716981064.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# INPUT_VOCAB_SIZE_TH = len(vocab_th)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# OUTPUT_VOCAB_SIZE_VI = len(vocab_vi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mINPUT_VOCAB_SIZE_SRC1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_vi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nguồn 1: Tiếng Việt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mINPUT_VOCAB_SIZE_SRC2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_th\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nguồn 2: Tiếng Thái\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mOUTPUT_VOCAB_SIZE_TGT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_en\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Đích: Tiếng Anh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab_vi' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm save/load checkpoint giữ nguyên\n",
        "def save_checkpoint(epoch, model, optimizer, scheduler, loss, filepath):\n",
        "    \"\"\"Lưu checkpoint.\"\"\"\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'loss': loss\n",
        "    }\n",
        "    torch.save(state, filepath)\n",
        "    print(f\"Checkpoint đã được lưu tại epoch {epoch} vào '{filepath}'\")\n",
        "\n",
        "def load_checkpoint(filepath, model, optimizer, scheduler):\n",
        "    \"\"\"Tải checkpoint.\"\"\"\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Không tìm thấy file checkpoint '{filepath}'. Bắt đầu huấn luyện từ đầu.\")\n",
        "        return 0, float('inf')\n",
        "\n",
        "    checkpoint = torch.load(filepath, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint.get('loss', float('inf'))\n",
        "    print(f\"Đã tải checkpoint từ epoch {epoch} với loss {loss:.4f} từ '{filepath}'\")\n",
        "    return epoch + 1, loss\n",
        "\n",
        "\n",
        "# Hàm train_epoch giữ nguyên\n",
        "def train_epoch(model, dataloader, optimizer, criterion, scaler, accumulation_steps):\n",
        "    \"\"\"Huấn luyện một epoch với Mixed Precision và Gradient Accumulation.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # for i, (src_en, src_th, tgt) in enumerate(dataloader):\n",
        "    #     src_en, src_th, tgt = src_en.to(device), src_th.to(device), tgt.to(device)\n",
        "    #     tgt_input = tgt[:, :-1]\n",
        "    #     tgt_output = tgt[:, 1:]\n",
        "\n",
        "    #     with autocast():\n",
        "    #         output = model(src_en, src_th, tgt_input)\n",
        "    #         loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n",
        "    #         loss = loss / accumulation_steps\n",
        "    for i, (src_vi, src_th, tgt_en) in enumerate(dataloader):\n",
        "        src_vi, src_th, tgt_en = src_vi.to(device), src_th.to(device), tgt_en.to(device)\n",
        "\n",
        "        tgt_input = tgt_en[:, :-1]\n",
        "        tgt_output = tgt_en[:, 1:]\n",
        "\n",
        "        with autocast():\n",
        "            # Truyền src1, src2, tgt theo đúng thứ tự của hàm forward\n",
        "            output = model(src_vi, src_th, tgt_input)\n",
        "            loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n",
        "            loss = loss / accumulation_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"  Batch {i+1}/{len(dataloader)}, Loss: {loss.item() * accumulation_steps:.4f}\")\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_loss = total_loss / len(dataloader)\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f\"Thời gian huấn luyện epoch: {epoch_time:.2f}s\")\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "# Hàm translate_sentence giữ nguyên\n",
        "def translate_sentence(sentence_en, sentence_th, model, max_len=50):\n",
        "    model.eval()\n",
        "    tokens_en = [BOS_IDX] + [vocab_en[token] for token in tokenize_en(sentence_en)] + [EOS_IDX]\n",
        "    tokens_th = [BOS_IDX] + [vocab_th[token] for token in tokenize_th(sentence_th)] + [EOS_IDX]\n",
        "    src_en_tensor_unbatched = torch.LongTensor(tokens_en).to(device)\n",
        "    src_th_tensor_unbatched = torch.LongTensor(tokens_th).to(device)\n",
        "    max_src_len = max(src_en_tensor_unbatched.size(0), src_th_tensor_unbatched.size(0))\n",
        "    pad_en_needed = max_src_len - src_en_tensor_unbatched.size(0)\n",
        "    pad_th_needed = max_src_len - src_th_tensor_unbatched.size(0)\n",
        "    src_en_tensor = F.pad(src_en_tensor_unbatched, (0, pad_en_needed), value=PAD_IDX).unsqueeze(0)\n",
        "    src_th_tensor = F.pad(src_th_tensor_unbatched, (0, pad_th_needed), value=PAD_IDX).unsqueeze(0)\n",
        "    tgt_tokens = [BOS_IDX]\n",
        "    for _ in range(max_len):\n",
        "        tgt_tensor = torch.LongTensor(tgt_tokens).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(src_en_tensor, src_th_tensor, tgt_tensor)\n",
        "        pred_token = output.argmax(2)[:, -1].item()\n",
        "        tgt_tokens.append(pred_token)\n",
        "        if pred_token == EOS_IDX:\n",
        "            break\n",
        "    tgt_words = [vocab_vi.get_itos()[i] for i in tgt_tokens]\n",
        "    return \" \".join(tgt_words[1:-1])\n",
        "# def translate_sentence(sentence_vi, sentence_th, model, max_len=50):\n",
        "#     model.eval()\n",
        "\n",
        "#     # Tokenize các ngôn ngữ nguồn mới\n",
        "#     tokens_vi = [BOS_IDX] + [vocab_vi[token] for token in tokenize_vi(sentence_vi)] + [EOS_IDX]\n",
        "#     tokens_th = [BOS_IDX] + [vocab_th[token] for token in tokenize_th(sentence_th)] + [EOS_IDX]\n",
        "\n",
        "#     src_vi_tensor = torch.LongTensor(tokens_vi).unsqueeze(0).to(device)\n",
        "#     src_th_tensor = torch.LongTensor(tokens_th).unsqueeze(0).to(device)\n",
        "\n",
        "#     # Padding đồng bộ (quan trọng cho inference)\n",
        "#     max_src_len = max(src_vi_tensor.size(1), src_th_tensor.size(1))\n",
        "#     src_vi_tensor = F.pad(src_vi_tensor, (0, max_src_len - src_vi_tensor.size(1)), value=PAD_IDX)\n",
        "#     src_th_tensor = F.pad(src_th_tensor, (0, max_src_len - src_th_tensor.size(1)), value=PAD_IDX)\n",
        "\n",
        "#     # Bắt đầu dịch với token <bos>\n",
        "#     tgt_tokens = [BOS_IDX]\n",
        "#     for _ in range(max_len):\n",
        "#         tgt_tensor = torch.LongTensor(tgt_tokens).unsqueeze(0).to(device)\n",
        "#         with torch.no_grad():\n",
        "#             output = model(src_vi_tensor, src_th_tensor, tgt_tensor)\n",
        "\n",
        "#         pred_token = output.argmax(2)[:, -1].item()\n",
        "#         tgt_tokens.append(pred_token)\n",
        "#         if pred_token == EOS_IDX:\n",
        "#             break\n",
        "\n",
        "#     # Chuyển index về lại từ vựng Tiếng Anh\n",
        "#     tgt_words = [vocab_en.get_itos()[i] for i in tgt_tokens]\n",
        "#     return \" \".join(tgt_words[1:-1])\n",
        "\n",
        "# ================= SỬA LỖI TẠI ĐÂY =================\n",
        "# Cập nhật hàm calculate_bleu để dọn dẹp bộ nhớ đúng cách\n",
        "def calculate_bleu(dataset, model, max_pairs=100):\n",
        "    targets = []\n",
        "    predictions = []\n",
        "    # Xử lý trường hợp dataset rỗng hoặc không có cặp nào để dịch\n",
        "    if len(dataset) == 0 or max_pairs == 0:\n",
        "        return 0.0\n",
        "\n",
        "    count = 0\n",
        "    for en_sent, th_sent, vi_sent in dataset:\n",
        "        if count >= max_pairs:\n",
        "            break\n",
        "        pred_sent = translate_sentence(en_sent, th_sent, model)\n",
        "        predictions.append(pred_sent)\n",
        "        targets.append([vi_sent])\n",
        "        count += 1\n",
        "\n",
        "    # Xử lý trường hợp không có dự đoán nào được tạo ra\n",
        "    if not predictions:\n",
        "        return 0.0\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(predictions, targets)\n",
        "\n",
        "    # 1. Lưu điểm số vào một biến mới\n",
        "    score_to_return = bleu.score\n",
        "\n",
        "    # 2. Xóa các biến lớn để giải phóng bộ nhớ\n",
        "    del targets, predictions, bleu\n",
        "    gc.collect()\n",
        "\n",
        "    # 3. Trả về điểm số đã lưu\n",
        "    return score_to_return\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "print(\"✅ Các hàm chức năng đã được cập nhật với logic dọn dẹp bộ nhớ chính xác!\")"
      ],
      "metadata": {
        "id": "KlSSB01HKvWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5af5d5a-a354-407a-8c1b-499ede403dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Các hàm chức năng đã được cập nhật với logic dọn dẹp bộ nhớ chính xác!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuẩn bị DataLoader\n",
        "full_dataset = TranslationDataset(VI_FILE_PATH, TH_FILE_PATH, EN_FILE_PATH)\n",
        "train_size = int(0.9 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Kích thước tập huấn luyện: {len(train_dataset)}\")\n",
        "print(f\"Kích thước tập validation: {len(val_dataset)}\")\n",
        "# Giải phóng bộ nhớ VRAM cuối epoch\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Tải checkpoint nếu có\n",
        "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, 'latest_checkpoint_optimized.pth') # Dùng tên file mới\n",
        "start_epoch, best_val_loss = load_checkpoint(CHECKPOINT_PATH, model, optimizer, scheduler)\n",
        "\n",
        "# Bắt đầu vòng lặp huấn luyện\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    print(f\"\\n--- Epoch {epoch}/{EPOCHS-1} ---\")\n",
        "    print(f\"Learning Rate hiện tại: {scheduler.get_last_lr()[0]}\")\n",
        "\n",
        "    # Huấn luyện\n",
        "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, scaler, GRADIENT_ACCUMULATION_STEPS)\n",
        "\n",
        "    # Cập nhật learning rate scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Đánh giá và tính BLEU trên tập validation\n",
        "    print(\"⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\")\n",
        "    model.eval()\n",
        "\n",
        "    # Lấy một vài câu từ validation set để dịch thử\n",
        "    sample_vi, sample_th, sample_en = val_dataset[0]\n",
        "    translated_sample = translate_sentence(sample_vi, sample_th, model)\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Câu nguồn (VI): {sample_vi}\")\n",
        "    print(f\"Câu nguồn (TH): {sample_th}\")\n",
        "    print(f\"Câu đích (EN) : {sample_en}\")\n",
        "    print(f\"Câu dịch model: {translated_sample}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "    # Lưu checkpoint\n",
        "    save_checkpoint(epoch, model, optimizer, scheduler, train_loss, CHECKPOINT_PATH)\n",
        "\n",
        "    # Tính điểm BLEU\n",
        "    #bleu_score = calculate_bleu(val_dataset, model, max_pairs=100)\n",
        "    #print(f\"Epoch {epoch} | BLEU score trên 200 câu validation: {bleu_score:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Giải phóng bộ nhớ VRAM cuối epoch\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n🎉 Huấn luyện hoàn tất! 🎉\")\n",
        "# Đánh giá và tính BLEU trên tập validation\n",
        "#print(\"⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\")\n",
        "#model.eval()\n",
        "\n",
        "# Tính điểm BLEU\n",
        "#bleu_score = calculate_bleu(val_dataset, model, max_pairs=7200)\n",
        "#print(f\"Epoch {EPOCHS} | BLEU score trên validation: {bleu_score:.2f}\")\n"
      ],
      "metadata": {
        "id": "LTe3TUHcMHrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144afe59-1596-46d0-c95d-79a55e3ab434",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kích thước tập huấn luyện: 68400\n",
            "Kích thước tập validation: 7600\n",
            "Đã tải checkpoint từ epoch 22 với loss 1.5187 từ '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en/latest_checkpoint_optimized.pth'\n",
            "\n",
            "--- Epoch 23/29 ---\n",
            "Learning Rate hiện tại: 3.138105960900002e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 100/4275, Loss: 2.1113\n",
            "  Batch 200/4275, Loss: 1.7864\n",
            "  Batch 300/4275, Loss: 1.3930\n",
            "  Batch 400/4275, Loss: 1.6814\n",
            "  Batch 500/4275, Loss: 1.2656\n",
            "  Batch 600/4275, Loss: 1.1284\n",
            "  Batch 700/4275, Loss: 1.4779\n",
            "  Batch 800/4275, Loss: 1.4848\n",
            "  Batch 900/4275, Loss: 1.9809\n",
            "  Batch 1000/4275, Loss: 1.8379\n",
            "  Batch 1100/4275, Loss: 1.5488\n",
            "  Batch 1200/4275, Loss: 2.0069\n",
            "  Batch 1300/4275, Loss: 1.5792\n",
            "  Batch 1400/4275, Loss: 1.3418\n",
            "  Batch 1500/4275, Loss: 1.2644\n",
            "  Batch 1600/4275, Loss: 1.8292\n",
            "  Batch 1700/4275, Loss: 1.5958\n",
            "  Batch 1800/4275, Loss: 1.8148\n",
            "  Batch 1900/4275, Loss: 1.0931\n",
            "  Batch 2000/4275, Loss: 1.6086\n",
            "  Batch 2100/4275, Loss: 1.5655\n",
            "  Batch 2200/4275, Loss: 1.3938\n",
            "  Batch 2300/4275, Loss: 1.4908\n",
            "  Batch 2400/4275, Loss: 1.9434\n",
            "  Batch 2500/4275, Loss: 1.3582\n",
            "  Batch 2600/4275, Loss: 1.4742\n",
            "  Batch 2700/4275, Loss: 1.6184\n",
            "  Batch 2800/4275, Loss: 1.6630\n",
            "  Batch 2900/4275, Loss: 1.6249\n",
            "  Batch 3000/4275, Loss: 1.5655\n",
            "  Batch 3100/4275, Loss: 1.6512\n",
            "  Batch 3200/4275, Loss: 1.7559\n",
            "  Batch 3300/4275, Loss: 1.4486\n",
            "  Batch 3400/4275, Loss: 1.7910\n",
            "  Batch 3500/4275, Loss: 1.1976\n",
            "  Batch 3600/4275, Loss: 1.4878\n",
            "  Batch 3700/4275, Loss: 1.6045\n",
            "  Batch 3800/4275, Loss: 1.4634\n",
            "  Batch 3900/4275, Loss: 1.6860\n",
            "  Batch 4000/4275, Loss: 1.4404\n",
            "  Batch 4100/4275, Loss: 1.6739\n",
            "  Batch 4200/4275, Loss: 2.0856\n",
            "Thời gian huấn luyện epoch: 596.47s\n",
            "Epoch 23 | Train Loss: 1.5789\n",
            "⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:384: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
            "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Câu nguồn (VI): Mã PIN có thể chưa được gửi đến bạn.\n",
            "Câu nguồn (TH): - เราอาจยังไม่ได้ส่ง PIN ถึงคุณ\n",
            "Câu đích (EN) : - A PIN might not have been sent to you.\n",
            "Câu dịch model: - A PIN may not be sent to you .\n",
            "------------------------------\n",
            "Checkpoint đã được lưu tại epoch 23 vào '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en/latest_checkpoint_optimized.pth'\n",
            "\n",
            "--- Epoch 24/29 ---\n",
            "Learning Rate hiện tại: 2.8242953648100018e-05\n",
            "  Batch 100/4275, Loss: 1.0239\n",
            "  Batch 200/4275, Loss: 1.1653\n",
            "  Batch 300/4275, Loss: 1.8168\n",
            "  Batch 400/4275, Loss: 1.8746\n",
            "  Batch 500/4275, Loss: 1.3151\n",
            "  Batch 600/4275, Loss: 0.8015\n",
            "  Batch 700/4275, Loss: 1.1125\n",
            "  Batch 800/4275, Loss: 1.0225\n",
            "  Batch 900/4275, Loss: 1.5843\n",
            "  Batch 1000/4275, Loss: 1.6802\n",
            "  Batch 1100/4275, Loss: 1.4955\n",
            "  Batch 1200/4275, Loss: 1.4479\n",
            "  Batch 1300/4275, Loss: 1.6725\n",
            "  Batch 1400/4275, Loss: 1.9877\n",
            "  Batch 1500/4275, Loss: 1.3663\n",
            "  Batch 1600/4275, Loss: 1.7287\n",
            "  Batch 1700/4275, Loss: 1.0977\n",
            "  Batch 1800/4275, Loss: 1.4129\n",
            "  Batch 1900/4275, Loss: 1.3576\n",
            "  Batch 2000/4275, Loss: 1.2653\n",
            "  Batch 2100/4275, Loss: 1.5187\n",
            "  Batch 2200/4275, Loss: 1.6634\n",
            "  Batch 2300/4275, Loss: 1.3913\n",
            "  Batch 2400/4275, Loss: 1.5266\n",
            "  Batch 2500/4275, Loss: 1.3242\n",
            "  Batch 2600/4275, Loss: 1.5234\n",
            "  Batch 2700/4275, Loss: 2.1020\n",
            "  Batch 2800/4275, Loss: 1.3062\n",
            "  Batch 2900/4275, Loss: 1.6519\n",
            "  Batch 3000/4275, Loss: 1.5996\n",
            "  Batch 3100/4275, Loss: 1.6816\n",
            "  Batch 3200/4275, Loss: 1.3940\n",
            "  Batch 3300/4275, Loss: 1.8342\n",
            "  Batch 3400/4275, Loss: 1.4936\n",
            "  Batch 3500/4275, Loss: 1.1466\n",
            "  Batch 3600/4275, Loss: 1.8227\n",
            "  Batch 3700/4275, Loss: 1.7469\n",
            "  Batch 3800/4275, Loss: 1.2597\n",
            "  Batch 3900/4275, Loss: 1.4127\n",
            "  Batch 4000/4275, Loss: 1.8065\n",
            "  Batch 4100/4275, Loss: 1.3461\n",
            "  Batch 4200/4275, Loss: 1.6327\n",
            "Thời gian huấn luyện epoch: 644.03s\n",
            "Epoch 24 | Train Loss: 1.4988\n",
            "⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\n",
            "------------------------------\n",
            "Câu nguồn (VI): Mã PIN có thể chưa được gửi đến bạn.\n",
            "Câu nguồn (TH): - เราอาจยังไม่ได้ส่ง PIN ถึงคุณ\n",
            "Câu đích (EN) : - A PIN might not have been sent to you.\n",
            "Câu dịch model: - A PIN may not be sent to you .\n",
            "------------------------------\n",
            "Checkpoint đã được lưu tại epoch 24 vào '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en/latest_checkpoint_optimized.pth'\n",
            "\n",
            "--- Epoch 25/29 ---\n",
            "Learning Rate hiện tại: 2.8242953648100018e-05\n",
            "  Batch 100/4275, Loss: 1.1843\n",
            "  Batch 200/4275, Loss: 1.1858\n",
            "  Batch 300/4275, Loss: 1.5678\n",
            "  Batch 400/4275, Loss: 1.1326\n",
            "  Batch 500/4275, Loss: 1.0922\n",
            "  Batch 600/4275, Loss: 1.2811\n",
            "  Batch 700/4275, Loss: 1.3355\n",
            "  Batch 800/4275, Loss: 1.8982\n",
            "  Batch 900/4275, Loss: 1.3457\n",
            "  Batch 1000/4275, Loss: 1.4309\n",
            "  Batch 1100/4275, Loss: 1.4918\n",
            "  Batch 1200/4275, Loss: 1.4221\n",
            "  Batch 1300/4275, Loss: 1.6656\n",
            "  Batch 1400/4275, Loss: 1.4680\n",
            "  Batch 1500/4275, Loss: 1.6727\n",
            "  Batch 1600/4275, Loss: 1.2632\n",
            "  Batch 1700/4275, Loss: 1.4969\n",
            "  Batch 1800/4275, Loss: 1.4005\n",
            "  Batch 1900/4275, Loss: 1.2944\n",
            "  Batch 2000/4275, Loss: 1.2259\n",
            "  Batch 2100/4275, Loss: 1.3965\n",
            "  Batch 2200/4275, Loss: 1.3225\n",
            "  Batch 2300/4275, Loss: 2.0122\n",
            "  Batch 2400/4275, Loss: 1.3724\n",
            "  Batch 2500/4275, Loss: 1.5586\n",
            "  Batch 2600/4275, Loss: 1.6880\n",
            "  Batch 2700/4275, Loss: 1.3340\n",
            "  Batch 2800/4275, Loss: 1.9427\n",
            "  Batch 2900/4275, Loss: 1.7219\n",
            "  Batch 3000/4275, Loss: 1.6168\n",
            "  Batch 3100/4275, Loss: 1.1695\n",
            "  Batch 3200/4275, Loss: 1.5407\n",
            "  Batch 3300/4275, Loss: 1.0035\n",
            "  Batch 3400/4275, Loss: 1.5275\n",
            "  Batch 3500/4275, Loss: 1.7370\n",
            "  Batch 3600/4275, Loss: 1.6875\n",
            "  Batch 3700/4275, Loss: 1.1668\n",
            "  Batch 3800/4275, Loss: 1.5466\n",
            "  Batch 3900/4275, Loss: 1.0564\n",
            "  Batch 4000/4275, Loss: 1.7085\n",
            "  Batch 4100/4275, Loss: 1.2355\n",
            "  Batch 4200/4275, Loss: 1.5019\n",
            "Thời gian huấn luyện epoch: 634.34s\n",
            "Epoch 25 | Train Loss: 1.4412\n",
            "⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\n",
            "------------------------------\n",
            "Câu nguồn (VI): Mã PIN có thể chưa được gửi đến bạn.\n",
            "Câu nguồn (TH): - เราอาจยังไม่ได้ส่ง PIN ถึงคุณ\n",
            "Câu đích (EN) : - A PIN might not have been sent to you.\n",
            "Câu dịch model: - A PIN may not be sent to you .\n",
            "------------------------------\n",
            "Checkpoint đã được lưu tại epoch 25 vào '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en/latest_checkpoint_optimized.pth'\n",
            "\n",
            "--- Epoch 26/29 ---\n",
            "Learning Rate hiện tại: 2.5418658283290016e-05\n",
            "  Batch 100/4275, Loss: 1.2360\n",
            "  Batch 200/4275, Loss: 1.1038\n",
            "  Batch 300/4275, Loss: 1.5862\n",
            "  Batch 400/4275, Loss: 1.1904\n",
            "  Batch 500/4275, Loss: 1.4777\n",
            "  Batch 600/4275, Loss: 1.0880\n",
            "  Batch 700/4275, Loss: 1.4355\n",
            "  Batch 800/4275, Loss: 1.2656\n",
            "  Batch 900/4275, Loss: 1.6710\n",
            "  Batch 1000/4275, Loss: 1.3535\n",
            "  Batch 1100/4275, Loss: 1.5474\n",
            "  Batch 1200/4275, Loss: 1.6443\n",
            "  Batch 1300/4275, Loss: 1.1691\n",
            "  Batch 1400/4275, Loss: 1.5694\n",
            "  Batch 1500/4275, Loss: 1.3728\n",
            "  Batch 1600/4275, Loss: 1.0156\n",
            "  Batch 1700/4275, Loss: 1.3866\n",
            "  Batch 1800/4275, Loss: 0.9751\n",
            "  Batch 1900/4275, Loss: 1.3943\n",
            "  Batch 2000/4275, Loss: 1.4712\n",
            "  Batch 2100/4275, Loss: 1.1631\n",
            "  Batch 2200/4275, Loss: 1.1766\n",
            "  Batch 2300/4275, Loss: 1.6407\n",
            "  Batch 2400/4275, Loss: 1.4561\n",
            "  Batch 2500/4275, Loss: 1.8858\n",
            "  Batch 2600/4275, Loss: 1.6151\n",
            "  Batch 2700/4275, Loss: 1.2040\n",
            "  Batch 2800/4275, Loss: 1.3743\n",
            "  Batch 2900/4275, Loss: 1.5172\n",
            "  Batch 3000/4275, Loss: 1.6947\n",
            "  Batch 3100/4275, Loss: 1.8149\n",
            "  Batch 3200/4275, Loss: 1.9234\n",
            "  Batch 3300/4275, Loss: 1.0797\n",
            "  Batch 3400/4275, Loss: 1.2898\n",
            "  Batch 3500/4275, Loss: 1.0276\n",
            "  Batch 3600/4275, Loss: 1.0978\n",
            "  Batch 3700/4275, Loss: 1.2213\n",
            "  Batch 3800/4275, Loss: 1.2512\n",
            "  Batch 3900/4275, Loss: 1.5913\n",
            "  Batch 4000/4275, Loss: 1.5608\n",
            "  Batch 4100/4275, Loss: 1.3902\n",
            "  Batch 4200/4275, Loss: 1.4539\n",
            "Thời gian huấn luyện epoch: 635.56s\n",
            "Epoch 26 | Train Loss: 1.3765\n",
            "⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\n",
            "------------------------------\n",
            "Câu nguồn (VI): Mã PIN có thể chưa được gửi đến bạn.\n",
            "Câu nguồn (TH): - เราอาจยังไม่ได้ส่ง PIN ถึงคุณ\n",
            "Câu đích (EN) : - A PIN might not have been sent to you.\n",
            "Câu dịch model: - A short - term is not sent to you .\n",
            "------------------------------\n",
            "Checkpoint đã được lưu tại epoch 26 vào '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en/latest_checkpoint_optimized.pth'\n",
            "\n",
            "--- Epoch 27/29 ---\n",
            "Learning Rate hiện tại: 2.5418658283290016e-05\n",
            "  Batch 100/4275, Loss: 1.7472\n",
            "  Batch 200/4275, Loss: 1.2956\n",
            "  Batch 300/4275, Loss: 0.8945\n",
            "  Batch 400/4275, Loss: 1.4344\n",
            "  Batch 500/4275, Loss: 0.8627\n",
            "  Batch 600/4275, Loss: 1.4399\n",
            "  Batch 700/4275, Loss: 1.3027\n",
            "  Batch 800/4275, Loss: 1.9107\n",
            "  Batch 900/4275, Loss: 1.0372\n",
            "  Batch 1000/4275, Loss: 1.3346\n",
            "  Batch 1100/4275, Loss: 1.3901\n",
            "  Batch 1200/4275, Loss: 1.5682\n",
            "  Batch 1300/4275, Loss: 1.5196\n",
            "  Batch 1400/4275, Loss: 1.5967\n",
            "  Batch 1500/4275, Loss: 1.4261\n",
            "  Batch 1600/4275, Loss: 1.5145\n",
            "  Batch 1700/4275, Loss: 1.2115\n",
            "  Batch 1800/4275, Loss: 1.6474\n",
            "  Batch 1900/4275, Loss: 1.1782\n",
            "  Batch 2000/4275, Loss: 0.8869\n",
            "  Batch 2100/4275, Loss: 1.3982\n",
            "  Batch 2200/4275, Loss: 0.8375\n",
            "  Batch 2300/4275, Loss: 1.2335\n",
            "  Batch 2400/4275, Loss: 1.2541\n",
            "  Batch 2500/4275, Loss: 1.1298\n",
            "  Batch 2600/4275, Loss: 1.4566\n",
            "  Batch 2700/4275, Loss: 1.2934\n",
            "  Batch 2800/4275, Loss: 1.1850\n",
            "  Batch 2900/4275, Loss: 1.5424\n",
            "  Batch 3000/4275, Loss: 1.0305\n",
            "  Batch 3100/4275, Loss: 1.2156\n",
            "  Batch 3200/4275, Loss: 1.4965\n",
            "  Batch 3300/4275, Loss: 0.9102\n",
            "  Batch 3400/4275, Loss: 1.5629\n",
            "  Batch 3500/4275, Loss: 1.4779\n",
            "  Batch 3600/4275, Loss: 1.2017\n",
            "  Batch 3700/4275, Loss: 1.0177\n",
            "  Batch 3800/4275, Loss: 1.2890\n",
            "  Batch 3900/4275, Loss: 1.2952\n",
            "  Batch 4000/4275, Loss: 1.1846\n",
            "  Batch 4100/4275, Loss: 1.4346\n",
            "  Batch 4200/4275, Loss: 1.4401\n",
            "Thời gian huấn luyện epoch: 630.37s\n",
            "Epoch 27 | Train Loss: 1.3284\n",
            "⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\n",
            "------------------------------\n",
            "Câu nguồn (VI): Mã PIN có thể chưa được gửi đến bạn.\n",
            "Câu nguồn (TH): - เราอาจยังไม่ได้ส่ง PIN ถึงคุณ\n",
            "Câu đích (EN) : - A PIN might not have been sent to you.\n",
            "Câu dịch model: - A PIN may not be sent to you .\n",
            "------------------------------\n",
            "Checkpoint đã được lưu tại epoch 27 vào '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en/latest_checkpoint_optimized.pth'\n",
            "\n",
            "--- Epoch 28/29 ---\n",
            "Learning Rate hiện tại: 2.2876792454961016e-05\n",
            "  Batch 100/4275, Loss: 0.9282\n",
            "  Batch 200/4275, Loss: 1.6246\n",
            "  Batch 300/4275, Loss: 1.0354\n",
            "  Batch 400/4275, Loss: 1.3142\n",
            "  Batch 500/4275, Loss: 1.3980\n",
            "  Batch 600/4275, Loss: 1.1052\n",
            "  Batch 700/4275, Loss: 1.2361\n",
            "  Batch 800/4275, Loss: 1.9392\n",
            "  Batch 900/4275, Loss: 0.9521\n",
            "  Batch 1000/4275, Loss: 1.1459\n",
            "  Batch 1100/4275, Loss: 1.2002\n",
            "  Batch 1200/4275, Loss: 0.7569\n",
            "  Batch 1300/4275, Loss: 0.9455\n",
            "  Batch 1400/4275, Loss: 0.8740\n",
            "  Batch 1500/4275, Loss: 1.4105\n",
            "  Batch 1600/4275, Loss: 1.1927\n",
            "  Batch 1700/4275, Loss: 1.4104\n",
            "  Batch 1800/4275, Loss: 1.5060\n",
            "  Batch 1900/4275, Loss: 1.1541\n",
            "  Batch 2000/4275, Loss: 1.3886\n",
            "  Batch 2100/4275, Loss: 1.6778\n",
            "  Batch 2200/4275, Loss: 1.1863\n",
            "  Batch 2300/4275, Loss: 1.1253\n",
            "  Batch 2400/4275, Loss: 1.7884\n",
            "  Batch 2500/4275, Loss: 1.0446\n",
            "  Batch 2600/4275, Loss: 1.2361\n",
            "  Batch 2700/4275, Loss: 1.0059\n",
            "  Batch 2800/4275, Loss: 0.7986\n",
            "  Batch 2900/4275, Loss: 1.0429\n",
            "  Batch 3000/4275, Loss: 1.4036\n",
            "  Batch 3100/4275, Loss: 1.8332\n",
            "  Batch 3200/4275, Loss: 0.8548\n",
            "  Batch 3300/4275, Loss: 1.4333\n",
            "  Batch 3400/4275, Loss: 1.1864\n",
            "  Batch 3500/4275, Loss: 1.1826\n",
            "  Batch 3600/4275, Loss: 1.1464\n",
            "  Batch 3700/4275, Loss: 1.6937\n",
            "  Batch 3800/4275, Loss: 1.3111\n",
            "  Batch 3900/4275, Loss: 1.2775\n",
            "  Batch 4000/4275, Loss: 1.0236\n",
            "  Batch 4100/4275, Loss: 1.3234\n",
            "  Batch 4200/4275, Loss: 1.4102\n",
            "Thời gian huấn luyện epoch: 626.58s\n",
            "Epoch 28 | Train Loss: 1.2767\n",
            "⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\n",
            "------------------------------\n",
            "Câu nguồn (VI): Mã PIN có thể chưa được gửi đến bạn.\n",
            "Câu nguồn (TH): - เราอาจยังไม่ได้ส่ง PIN ถึงคุณ\n",
            "Câu đích (EN) : - A PIN might not have been sent to you.\n",
            "Câu dịch model: - A connection is sent to you .\n",
            "------------------------------\n",
            "Checkpoint đã được lưu tại epoch 28 vào '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en/latest_checkpoint_optimized.pth'\n",
            "\n",
            "--- Epoch 29/29 ---\n",
            "Learning Rate hiện tại: 2.2876792454961016e-05\n",
            "  Batch 100/4275, Loss: 1.5025\n",
            "  Batch 200/4275, Loss: 0.9251\n",
            "  Batch 300/4275, Loss: 1.5375\n",
            "  Batch 400/4275, Loss: 1.1823\n",
            "  Batch 500/4275, Loss: 1.1771\n",
            "  Batch 600/4275, Loss: 1.3723\n",
            "  Batch 700/4275, Loss: 1.4823\n",
            "  Batch 800/4275, Loss: 1.3711\n",
            "  Batch 900/4275, Loss: 0.7603\n",
            "  Batch 1000/4275, Loss: 1.2335\n",
            "  Batch 1100/4275, Loss: 1.4076\n",
            "  Batch 1200/4275, Loss: 1.2321\n",
            "  Batch 1300/4275, Loss: 1.3695\n",
            "  Batch 1400/4275, Loss: 1.2722\n",
            "  Batch 1500/4275, Loss: 1.1567\n",
            "  Batch 1600/4275, Loss: 1.3724\n",
            "  Batch 1700/4275, Loss: 0.7976\n",
            "  Batch 1800/4275, Loss: 1.0355\n",
            "  Batch 1900/4275, Loss: 1.1079\n",
            "  Batch 2000/4275, Loss: 0.9481\n",
            "  Batch 2100/4275, Loss: 1.6351\n",
            "  Batch 2200/4275, Loss: 1.5092\n",
            "  Batch 2300/4275, Loss: 1.4329\n",
            "  Batch 2400/4275, Loss: 0.9942\n",
            "  Batch 2500/4275, Loss: 1.1554\n",
            "  Batch 2600/4275, Loss: 1.0519\n",
            "  Batch 2700/4275, Loss: 1.0970\n",
            "  Batch 2800/4275, Loss: 0.8535\n",
            "  Batch 2900/4275, Loss: 0.7988\n",
            "  Batch 3000/4275, Loss: 1.2227\n",
            "  Batch 3100/4275, Loss: 1.2404\n",
            "  Batch 3200/4275, Loss: 1.0787\n",
            "  Batch 3300/4275, Loss: 1.4136\n",
            "  Batch 3400/4275, Loss: 0.8088\n",
            "  Batch 3500/4275, Loss: 1.1274\n",
            "  Batch 3600/4275, Loss: 1.2904\n",
            "  Batch 3700/4275, Loss: 1.1328\n",
            "  Batch 3800/4275, Loss: 1.5713\n",
            "  Batch 3900/4275, Loss: 1.1858\n",
            "  Batch 4000/4275, Loss: 1.1286\n",
            "  Batch 4100/4275, Loss: 1.1193\n",
            "  Batch 4200/4275, Loss: 1.4952\n",
            "Thời gian huấn luyện epoch: 628.78s\n",
            "Epoch 29 | Train Loss: 1.2350\n",
            "⚙️ Đang đánh giá trên tập validation và tính điểm BLEU...\n",
            "------------------------------\n",
            "Câu nguồn (VI): Mã PIN có thể chưa được gửi đến bạn.\n",
            "Câu nguồn (TH): - เราอาจยังไม่ได้ส่ง PIN ถึงคุณ\n",
            "Câu đích (EN) : - A PIN might not have been sent to you.\n",
            "Câu dịch model: - A connection is not sent to you .\n",
            "------------------------------\n",
            "Checkpoint đã được lưu tại epoch 29 vào '/content/drive/MyDrive/TieuLuanNLP/model/multisource_vi_en/latest_checkpoint_optimized.pth'\n",
            "\n",
            "🎉 Huấn luyện hoàn tất! 🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker sacrebleu pythainlp underthesea torchtext==0.17.0 --quiet\n",
        "# 1. Cài đặt thư viện LIME\n",
        "print(\"⚙️ Đang cài đặt thư viện LIME...\")\n",
        "# Thêm phiên bản cụ thể cho LIME\n",
        "!pip install lime\n",
        "print(\"✅ Cài đặt LIME hoàn tất!\")\n",
        "# Fix: Install a compatible version of numpy to avoid conflicts\n",
        "!pip install numpy==1.26.4 --quiet\n",
        "\n",
        "# IMPORTANT: Restart the runtime after running this cell.\n",
        "# Go to \"Runtime\" -> \"Restart runtime\"."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2ysT7lYI6Zk",
        "outputId": "ab46b857-f04c-471f-8e7b-73dbcb9c69fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Đang cài đặt thư viện LIME...\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=b61fbf1936afad160fbfa82499f15aca6e9784d6586d7f567e83bf57999fef66\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n",
            "✅ Cài đặt LIME hoàn tất!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL A: LƯU MODEL CUỐI CÙNG SAU KHI HUẤN LUYỆN ---\n",
        "\n",
        "# Kiểm tra xem mô hình đã được huấn luyện chưa\n",
        "if 'model' in locals() and isinstance(model, nn.Module):\n",
        "    # Định nghĩa đường dẫn và tên file cho mô hình cuối cùng\n",
        "    FINAL_MODEL_PATH = os.path.join(CHECKPOINT_DIR, 'final_multisource_translator.pth')\n",
        "\n",
        "    print(f\"\\n⚙️ Đang đóng gói và lưu mô hình cuối cùng...\")\n",
        "\n",
        "    # Tạo một dictionary để lưu tất cả các thành phần quan trọng\n",
        "    model_save_package = {\n",
        "        'epoch': EPOCHS,  # Lưu lại epoch cuối cùng đã hoàn thành\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'd_model': D_MODEL, 'num_heads': NUM_HEADS, 'num_encoder_layers': NUM_ENCODER_LAYERS,\n",
        "        'num_decoder_layers': NUM_DECODER_LAYERS, 'd_ff': D_FF, 'dropout': DROPOUT,\n",
        "        'vocab_en': vocab_en, 'vocab_th': vocab_th, 'vocab_vi': vocab_vi,\n",
        "        'pad_idx': PAD_IDX,\n",
        "    }\n",
        "\n",
        "    # Thực hiện lưu file bằng lệnh torch.save() tiêu chuẩn\n",
        "    torch.save(model_save_package, FINAL_MODEL_PATH)\n",
        "\n",
        "    print(f\"✅ Model cuối cùng đã được lưu thành công tại: {FINAL_MODEL_PATH}\")\n",
        "else:\n",
        "    print(\"Lỗi: Không tìm thấy biến 'model'. Hãy đảm bảo bạn đã chạy các cell huấn luyện trước đó.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtlkfXV8mK9Q",
        "outputId": "59b16399-eeb9-4adf-ef72-4d9602c1c85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lỗi: Không tìm thấy biến 'model'. Hãy đảm bảo bạn đã chạy các cell huấn luyện trước đó.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL B: TẢI LẠI MODEL ĐỂ SỬ DỤNG (INFERENCE) ---\n",
        "\n",
        "import math\n",
        "import spacy\n",
        "from pythainlp.tokenize import word_tokenize as th_word_tokenize\n",
        "from underthesea import word_tokenize as vi_word_tokenize\n",
        "import torch.nn.functional as F\n",
        "# 1. Định nghĩa các đường dẫn và thiết bị\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/TieuLuanNLP/model/multisource_en_vi'\n",
        "FINAL_MODEL_PATH = os.path.join(CHECKPOINT_DIR, 'final_multisource_translator.pth')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 2. Tải file model đã đóng gói\n",
        "print(f\"⚙️ Đang tải model package từ: {FINAL_MODEL_PATH}\")\n",
        "model_package = torch.load(FINAL_MODEL_PATH, map_location=device, weights_only=False)\n",
        "\n",
        "# 3. Khôi phục lại các thành phần từ package\n",
        "# Lấy lại vocabularies\n",
        "vocab_en = model_package['vocab_en']\n",
        "vocab_th = model_package['vocab_th']\n",
        "vocab_vi = model_package['vocab_vi']\n",
        "PAD_IDX = model_package['pad_idx']\n",
        "BOS_IDX = vocab_vi.get_stoi()['<bos>'] # Lấy lại BOS_IDX từ vocab\n",
        "EOS_IDX = vocab_vi.get_stoi()['<eos>'] # Lấy lại EOS_IDX từ vocab\n",
        "\n",
        "# Lấy lại các hyperparameters để khởi tạo đúng kiến trúc model\n",
        "D_MODEL = model_package['d_model']\n",
        "NUM_HEADS = model_package['num_heads']\n",
        "NUM_ENCODER_LAYERS = model_package['num_encoder_layers']\n",
        "NUM_DECODER_LAYERS = model_package['num_decoder_layers']\n",
        "D_FF = model_package['d_ff']\n",
        "DROPOUT = model_package['dropout']\n",
        "\n",
        "INPUT_VOCAB_SIZE_EN = len(vocab_en)\n",
        "INPUT_VOCAB_SIZE_TH = len(vocab_th)\n",
        "OUTPUT_VOCAB_SIZE_VI = len(vocab_vi)\n",
        "\n",
        "# 4. Khởi tạo một model rỗng và nạp trọng số vào\n",
        "print(\"⚙️ Đang khởi tạo kiến trúc model và nạp trọng số...\")\n",
        "inference_model = MultiSourceTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, D_MODEL, NUM_HEADS,\n",
        "                                       INPUT_VOCAB_SIZE_EN, INPUT_VOCAB_SIZE_TH, OUTPUT_VOCAB_SIZE_VI,\n",
        "                                       D_FF, DROPOUT).to(device)\n",
        "\n",
        "inference_model.load_state_dict(model_package['model_state_dict'])\n",
        "inference_model.eval() # Chuyển model sang chế độ đánh giá\n",
        "\n",
        "print(\"✅ Model đã sẵn sàng để dịch thuật!\")\n",
        "\n",
        "# 5. Dịch thử một câu để kiểm tra\n",
        "en_test_sentence = \"This is a test\"\n",
        "th_test_sentence = \"นี่คือการทดสอบ\" # \"Đây là một bài kiểm tra\"\n",
        "\n",
        "# Phải định nghĩa lại các hàm tokenize\n",
        "nlp_en = spacy.load('en_core_web_sm')\n",
        "def tokenize_en(text): return [tok.text for tok in nlp_en.tokenizer(text)]\n",
        "def tokenize_th(text): return th_word_tokenize(text)\n",
        "def tokenize_vi(text): return vi_word_tokenize(text)\n",
        "\n",
        "translated_text = translate_sentence(en_test_sentence, th_test_sentence, inference_model)\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(f\"Câu nguồn (EN): {en_test_sentence}\")\n",
        "print(f\"Câu nguồn (TH): {th_test_sentence}\")\n",
        "print(f\"Câu dịch model: {translated_text}\")\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRZNtJQMJc2T",
        "outputId": "99a7c534-e950-4797-8422-14cce654bb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Đang tải model package từ: /content/drive/MyDrive/TieuLuanNLP/model/multisource_en_vi/final_multisource_translator.pth\n",
            "⚙️ Đang khởi tạo kiến trúc model và nạp trọng số...\n",
            "✅ Model đã sẵn sàng để dịch thuật!\n",
            "------------------------------\n",
            "Câu nguồn (EN): This is a test\n",
            "Câu nguồn (TH): นี่คือการทดสอบ\n",
            "Câu dịch model: Đây là một bài kiểm tra\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL ĐỂ TEST MÔ HÌNH VỚI 10 CÂU VÍ DỤ ---\n",
        "\n",
        "# Kiểm tra xem mô hình `inference_model` đã tồn tại và sẵn sàng chưa\n",
        "if 'inference_model' in locals() and isinstance(inference_model, nn.Module):\n",
        "\n",
        "    # 1. Chuẩn bị 10 câu ví dụ\n",
        "    # Lưu ý: Vì model của chúng ta là đa nguồn, nó cần cả đầu vào tiếng Anh và tiếng Thái.\n",
        "    # Ở đây tôi cung cấp các cặp câu tương ứng. Nếu bạn chỉ có câu tiếng Anh,\n",
        "    # bạn có thể truyền một chuỗi rỗng \"\" cho phần tiếng Thái.\n",
        "\n",
        "    sample_english = [\n",
        "        \"Brother Albert Barnett and his wife , Sister Susan Barnett , from the West Congregation in Tuscaloosa , Alabama\",\n",
        "        \"Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12 , 2020 .\",\n",
        "        \"Two days of heavy rain , high winds , and numerous tornadoes caused major damage across multiple states .\",\n",
        "        \"Sadly , Brother Albert Barnett and his wife , Sister Susan Barnett , 85 and 75 years old respectively , were killed when a tornado struck their mobile home .\",\n",
        "        \"The United States branch also reports that at least four of our brothers' homes sustained minor damage , along with two Kingdom Halls .\",\n",
        "        \"Additionally , the storms caused major damage to a brother 's business property .\",\n",
        "        \"Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster .\",\n",
        "        \"We know that our heavenly Father , Jehovah , is providing comfort to our brothers and sisters who are grieving because of this tragedy .\",\n",
        "        \"International government agencies and officials have responded to Russia 's Supreme Court decision that criminalizes the worship of Jehovah 's Witnesses in Russia .\",\n",
        "        \"These statements have criticized Russia 's unjust and harsh judicial action against a minority religious group known for peaceful religious activity .\"\n",
        "    ]\n",
        "\n",
        "    sample_thai = [\n",
        "        \"บราเดอร์อัลเบิร์ต บาร์เน็ตต์ และซิสเตอร์ซูซาน บาร์เน็ตต์ ภรรยาของเขา จากคริสตจักรเวสต์คองเกรสในเมืองทัสคาลูซา รัฐแอละแบมา\",\n",
        "        \"พายุรุนแรงพัดถล่มพื้นที่ทางตอนใต้และตะวันตกกลางของสหรัฐอเมริกาเมื่อวันที่ 11 และ 12 มกราคม 2020\",\n",
        "        \"ฝนตกหนักสองวัน ลมแรง และพายุทอร์นาโดหลายลูกสร้างความเสียหายอย่างหนักในหลายรัฐ\",\n",
        "        \"น่าเศร้าที่บราเดอร์อัลเบิร์ต บาร์เน็ตต์ และซิสเตอร์ซูซาน บาร์เน็ตต์ ภรรยาของเขา อายุ 85 ปี และ 75 ปี ตามลำดับ เสียชีวิตเมื่อพายุทอร์นาโดพัดถล่มบ้านเคลื่อนที่ของพวกเขา\",\n",
        "        \"สาขาในสหรัฐอเมริกายังรายงานว่าบ้านของบราเดอร์อย่างน้อยสี่หลังได้รับความเสียหายเล็กน้อย พร้อมกับหอประชุมราชอาณาจักรสองหลัง\",\n",
        "        \"นอกจากนี้ พายุยังสร้างความเสียหายอย่างหนักต่อทรัพย์สินทางธุรกิจของบราเดอร์ท่านหนึ่ง\",\n",
        "        \"ผู้อาวุโสในท้องถิ่นและผู้ดูแลภาคกำลังให้การสนับสนุนทั้งในทางปฏิบัติและทางจิตวิญญาณแก่ผู้ที่ได้รับผลกระทบจากภัยพิบัติครั้งนี้\",\n",
        "        \"เรารู้ว่าพระบิดาบนสวรรค์ พระยะโฮวา ทรงประทานการปลอบโยนแก่พี่น้องชายหญิงของเราที่กำลังโศกเศร้าเสียใจจากโศกนาฏกรรมครั้งนี้\",\n",
        "        \"หน่วยงานรัฐบาลระหว่างประเทศและเจ้าหน้าที่ได้ออกมาตอบโต้คำตัดสินของศาลฎีการัสเซียที่ทำให้การนมัสการพยานพระยะโฮวาในรัสเซียเป็นความผิดทางอาญา\",\n",
        "        \"คำแถลงเหล่านี้วิพากษ์วิจารณ์การดำเนินการทางกฎหมายที่ไม่ยุติธรรมและรุนแรงของรัสเซียต่อกลุ่มศาสนาชนกลุ่มน้อยที่ขึ้นชื่อเรื่องการดำเนินกิจกรรมทางศาสนาอย่างสันติ\",\n",
        "    ]\n",
        "\n",
        "    # Đây là các câu dịch đúng để chúng ta so sánh\n",
        "    sample_vietnamese = [\n",
        "        \"Anh Albert Barnett và chị Susan Barnett , thuộc hội thánh West ở Tuscaloosa , Alabama\",\n",
        "        \"Ngày 11 và 12-1-2020 , những cơn bão lớn đã quét qua và phá huỷ nhiều vùng ở miền nam và miền trung Hoa Kỳ .\",\n",
        "        \"Những trận mưa to và gió lớn trong suốt hai ngày cùng với nhiều cơn lốc xoáy đã gây thiệt hại nặng nề cho nhiều bang .\",\n",
        "        \"Đáng buồn là anh Albert Barnett 85 tuổi , và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ .\",\n",
        "        \"Chi nhánh Hoa Kỳ cũng cho biết có ít nhất bốn căn nhà của anh em chúng tôi và hai Phòng Nước Trời bị hư hại nhẹ .\",\n",
        "        \"Ngoài ra , những cơn bão cũng gây hư hại lớn cho cơ sở kinh doanh của một anh em .\",\n",
        "        \"Các trưởng lão địa phương và giám thị xung quanh đang giúp đỡ và cung cấp về vật chất và tinh thần cho các anh chị bị ảnh hưởng trong thảm hoạ này .\",\n",
        "        \"Chúng ta tin chắc rằng Cha trên trời , Đức Giê-hô-va , đang an ủi những anh chị em của chúng ta trong cảnh đau buồn .\",\n",
        "        \"Các cơ quan và viên chức chính phủ quốc tế đã lên tiếng trước phán quyết của Toà Tối Cao Nga về việc cấm sự thờ phượng của Nhân Chứng Giê-hô-va ở Nga .\",\n",
        "        \"Các lời nhận xét chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà .\"\n",
        "    ]\n",
        "\n",
        "    print(\" BẮT ĐẦU KIỂM TRA MÔ HÌNH VỚI 10 CÂU VÍ DỤ \".center(80, \"=\"))\n",
        "\n",
        "    # 2. Dịch từng câu và in kết quả\n",
        "    for i in range(len(sample_english)):\n",
        "        en_sent = sample_english[i]\n",
        "        th_sent = sample_thai[i]\n",
        "        vi_ref = sample_vietnamese[i]\n",
        "\n",
        "        # Gọi hàm dịch đã được định nghĩa ở các cell trước\n",
        "        model_translation = translate_sentence(en_sent, th_sent, inference_model)\n",
        "\n",
        "        print(f\"\\n--- CÂU {i+1} ---\")\n",
        "        print(f\"  > Tiếng Anh (Input 1):\".ljust(25), f\"{en_sent}\")\n",
        "        print(f\"  > Tiếng Thái (Input 2):\".ljust(25), f\"{th_sent}\")\n",
        "        print(f\"  > Bản dịch tham khảo:\".ljust(25), f\"{vi_ref}\")\n",
        "        print(f\"  > BẢN DỊCH CỦA MODEL:\".ljust(25), f\"{model_translation}\")\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"✅ Hoàn tất kiểm tra.\")\n",
        "\n",
        "else:\n",
        "    print(\"Lỗi: Model chưa được tải. Vui lòng chạy cell tải model (Cell B) trước khi chạy cell này.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PDf6U-JKINB",
        "outputId": "24e67a87-9914-466d-f238-57f1af1fa219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lỗi: Model chưa được tải. Vui lòng chạy cell tải model (Cell B) trước khi chạy cell này.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL E: GIẢI THÍCH MODEL BẰNG KỸ THUẬT XAI LIME ---\n",
        "\n",
        "# 2. Import các thư viện cần thiết\n",
        "import lime\n",
        "import lime.lime_text\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "import sacrebleu\n",
        "from IPython.display import display, HTML\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "\n",
        "# Kiểm tra xem mô hình `inference_model` đã tồn tại và sẵn sàng chưa\n",
        "if 'inference_model' in locals() and isinstance(inference_model, nn.Module):\n",
        "\n",
        "    # 2. Xây dựng một hàm \"dự đoán\" mới cho LIME ở chế độ Hồi quy\n",
        "    # Hàm này sẽ trả về một điểm số chất lượng (thay vì xác suất) cho mỗi câu dịch.\n",
        "    # Chúng ta sẽ dùng điểm SENTENCE-BLEU làm điểm chất lượng.\n",
        "\n",
        "    # 2. Xây dựng hàm \"dự đoán\" mới, phỏng theo mã mẫu của bạn\n",
        "    def lime_multisource_predictor(texts):\n",
        "        \"\"\"\n",
        "        Hàm này nhận một danh sách các câu đã bị LIME xáo trộn,\n",
        "        và trả về một mảng xác suất cho token ĐẦU TIÊN của câu dịch.\n",
        "        Shape trả về: (số câu, kích thước bộ từ vựng đích)\n",
        "        \"\"\"\n",
        "        en_batch_tensors, th_batch_tensors = [], []\n",
        "\n",
        "        # Tách và token hóa từng câu\n",
        "        for text in texts:\n",
        "            parts = text.split(' ; ') # Phải có khoảng trắng để tránh lỗi dính chữ\n",
        "            en_sent = parts[0]\n",
        "            th_sent = parts[1] if len(parts) > 1 else \"\"\n",
        "\n",
        "            en_tokens = [BOS_IDX] + [vocab_en[tok] for tok in tokenize_en(en_sent)] + [EOS_IDX]\n",
        "            th_tokens = [BOS_IDX] + [vocab_th[tok] for tok in tokenize_th(th_sent)] + [EOS_IDX]\n",
        "\n",
        "            en_batch_tensors.append(torch.LongTensor(en_tokens))\n",
        "            th_batch_tensors.append(torch.LongTensor(th_tokens))\n",
        "\n",
        "        # Padding đồng bộ cho cả 2 ngôn ngữ nguồn\n",
        "        en_padded = pad_sequence(en_batch_tensors, batch_first=True, padding_value=PAD_IDX)\n",
        "        th_padded = pad_sequence(th_batch_tensors, batch_first=True, padding_value=PAD_IDX)\n",
        "        max_len = max(en_padded.size(1), th_padded.size(1))\n",
        "\n",
        "        if en_padded.size(1) < max_len:\n",
        "            en_padded = F.pad(en_padded, (0, max_len - en_padded.size(1)), 'constant', PAD_IDX)\n",
        "        if th_padded.size(1) < max_len:\n",
        "            th_padded = F.pad(th_padded, (0, max_len - th_padded.size(1)), 'constant', PAD_IDX)\n",
        "\n",
        "        src_en = en_padded.to(device)\n",
        "        src_th = th_padded.to(device)\n",
        "\n",
        "        # Tạo đầu vào cho decoder: chỉ có token <BOS> để dự đoán từ đầu tiên\n",
        "        batch_size = src_en.size(0)\n",
        "        tgt_input = torch.LongTensor([[BOS_IDX]] * batch_size).to(device)\n",
        "\n",
        "        # Chạy model\n",
        "        with torch.no_grad():\n",
        "            logits = inference_model(src_en, src_th, tgt_input)\n",
        "\n",
        "        # Logits có shape: [batch_size, 1, vocab_size]\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        # Chuyển logits thành xác suất\n",
        "        probs = probs[:, 0, :]\n",
        "\n",
        "        return probs.cpu().numpy()\n",
        "    # 3. Khởi tạo LIME Explainer ở chế độ 'regression'\n",
        "    explainer = LimeTextExplainer(class_names=[\"vi\"])\n",
        "\n",
        "    # Lấy lại 10 câu ví dụ từ cell trước\n",
        "    sample_english = [\n",
        "        \"Brother Albert Barnett and his wife , Sister Susan Barnett , from the West Congregation in Tuscaloosa , Alabama\",\n",
        "        \"Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12 , 2020 .\",\n",
        "        \"Two days of heavy rain , high winds , and numerous tornadoes caused major damage across multiple states .\",\n",
        "        \"Sadly , Brother Albert Barnett and his wife , Sister Susan Barnett , 85 and 75 years old respectively , were killed when a tornado struck their mobile home .\",\n",
        "        \"The United States branch also reports that at least four of our brothers' homes sustained minor damage , along with two Kingdom Halls .\",\n",
        "        \"Additionally , the storms caused major damage to a brother 's business property .\",\n",
        "        \"Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster .\",\n",
        "        \"We know that our heavenly Father , Jehovah , is providing comfort to our brothers and sisters who are grieving because of this tragedy .\",\n",
        "        \"International government agencies and officials have responded to Russia 's Supreme Court decision that criminalizes the worship of Jehovah 's Witnesses in Russia .\",\n",
        "        \"These statements have criticized Russia 's unjust and harsh judicial action against a minority religious group known for peaceful religious activity .\"\n",
        "\n",
        "    ]\n",
        "    sample_thai = [\n",
        "        \"บราเดอร์อัลเบิร์ต บาร์เน็ตต์ และซิสเตอร์ซูซาน บาร์เน็ตต์ ภรรยาของเขา จากคริสตจักรเวสต์คองเกรสในเมืองทัสคาลูซา รัฐแอละแบมา\",\n",
        "        \"พายุรุนแรงพัดถล่มพื้นที่ทางตอนใต้และตะวันตกกลางของสหรัฐอเมริกาเมื่อวันที่ 11 และ 12 มกราคม 2020\",\n",
        "        \"ฝนตกหนักสองวัน ลมแรง และพายุทอร์นาโดหลายลูกสร้างความเสียหายอย่างหนักในหลายรัฐ\",\n",
        "        \"น่าเศร้าที่บราเดอร์อัลเบิร์ต บาร์เน็ตต์ และซิสเตอร์ซูซาน บาร์เน็ตต์ ภรรยาของเขา อายุ 85 ปี และ 75 ปี ตามลำดับ เสียชีวิตเมื่อพายุทอร์นาโดพัดถล่มบ้านเคลื่อนที่ของพวกเขา\",\n",
        "        \"สาขาในสหรัฐอเมริกายังรายงานว่าบ้านของบราเดอร์อย่างน้อยสี่หลังได้รับความเสียหายเล็กน้อย พร้อมกับหอประชุมราชอาณาจักรสองหลัง\",\n",
        "        \"นอกจากนี้ พายุยังสร้างความเสียหายอย่างหนักต่อทรัพย์สินทางธุรกิจของบราเดอร์ท่านหนึ่ง\",\n",
        "        \"ผู้อาวุโสในท้องถิ่นและผู้ดูแลภาคกำลังให้การสนับสนุนทั้งในทางปฏิบัติและทางจิตวิญญาณแก่ผู้ที่ได้รับผลกระทบจากภัยพิบัติครั้งนี้\",\n",
        "        \"เรารู้ว่าพระบิดาบนสวรรค์ พระยะโฮวา ทรงประทานการปลอบโยนแก่พี่น้องชายหญิงของเราที่กำลังโศกเศร้าเสียใจจากโศกนาฏกรรมครั้งนี้\",\n",
        "        \"หน่วยงานรัฐบาลระหว่างประเทศและเจ้าหน้าที่ได้ออกมาตอบโต้คำตัดสินของศาลฎีการัสเซียที่ทำให้การนมัสการพยานพระยะโฮวาในรัสเซียเป็นความผิดทางอาญา\",\n",
        "        \"คำแถลงเหล่านี้วิพากษ์วิจารณ์การดำเนินการทางกฎหมายที่ไม่ยุติธรรมและรุนแรงของรัสเซียต่อกลุ่มศาสนาชนกลุ่มน้อยที่ขึ้นชื่อเรื่องการดำเนินกิจกรรมทางศาสนาอย่างสันติ\",\n",
        "    ]\n",
        "    sample_vietnamese = [\n",
        "        \"Anh Albert Barnett và chị Susan Barnett , thuộc hội thánh West ở Tuscaloosa , Alabama\",\n",
        "        \"Ngày 11 và 12-1-2020 , những cơn bão lớn đã quét qua và phá huỷ nhiều vùng ở miền nam và miền trung Hoa Kỳ .\",\n",
        "        \"Những trận mưa to và gió lớn trong suốt hai ngày cùng với nhiều cơn lốc xoáy đã gây thiệt hại nặng nề cho nhiều bang .\",\n",
        "        \"Đáng buồn là anh Albert Barnett 85 tuổi , và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ .\",\n",
        "        \"Chi nhánh Hoa Kỳ cũng cho biết có ít nhất bốn căn nhà của anh em chúng tôi và hai Phòng Nước Trời bị hư hại nhẹ .\",\n",
        "        \"Ngoài ra , những cơn bão cũng gây hư hại lớn cho cơ sở kinh doanh của một anh em .\",\n",
        "        \"Các trưởng lão địa phương và giám thị xung quanh đang giúp đỡ và cung cấp về vật chất và tinh thần cho các anh chị bị ảnh hưởng trong thảm hoạ này .\",\n",
        "        \"Chúng ta tin chắc rằng Cha trên trời , Đức Giê-hô-va , đang an ủi những anh chị em của chúng ta trong cảnh đau buồn .\",\n",
        "        \"Các cơ quan và viên chức chính phủ quốc tế đã lên tiếng trước phán quyết của Toà Tối Cao Nga về việc cấm sự thờ phượng của Nhân Chứng Giê-hô-va ở Nga .\",\n",
        "        \"Các lời nhận xét chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà .\"\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    print(\" BẮT ĐẦU GIẢI THÍCH MÔ HÌNH BẰNG LIME \".center(80, \"=\"))\n",
        "\n",
        "    # 5. Chạy LIME cho từng câu\n",
        "    for i in range(len(sample_english)):\n",
        "        en_sent = sample_english[i]\n",
        "        th_sent = sample_thai[i]\n",
        "        vi_ref = sample_vietnamese[i]\n",
        "\n",
        "        text_to_explain = f\"{en_sent} ; {th_sent}\"\n",
        "\n",
        "        print(f\"\\n--- GIẢI THÍCH CHO CÂU {i+1} ---\")\n",
        "        print(f\"Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: '{en_sent}'\")\n",
        "\n",
        "\n",
        "        # Chạy giải thích của LIME\n",
        "        # num_features: số từ quan trọng nhất muốn xem\n",
        "        # num_samples: số câu xáo trộn LIME tạo ra để thử nghiệm\n",
        "        explanation = explainer.explain_instance(\n",
        "            text_to_explain,\n",
        "            lime_multisource_predictor,\n",
        "            num_features=6, # Lấy 6 từ ảnh hưởng nhất\n",
        "            num_samples=500 # Tăng num_samples để kết quả ổn định hơn\n",
        "        )\n",
        "\n",
        "        # Hiển thị kết quả giải thích trực quan trong notebook\n",
        "        #display(HTML(explanation.as_html()))\n",
        "        print(f\"Explanation: {explanation.as_list()}\\n\")\n",
        "else:\n",
        "    print(\"Lỗi: Model chưa được tải. Vui lòng chạy cell tải model (Cell B) trước khi chạy cell này.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wiz7NmfBa5wm",
        "outputId": "53ae9635-3a08-4062-a6c7-39b94c950cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================== BẮT ĐẦU GIẢI THÍCH MÔ HÌNH BẰNG LIME =====================\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 1 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'Brother Albert Barnett and his wife , Sister Susan Barnett , from the West Congregation in Tuscaloosa , Alabama'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('Sister', -9.458128371254788e-09), ('บาร', -6.983643577817748e-09), ('Alabama', 6.586893231817712e-09), ('กรเวสต', -6.581261933728665e-09), ('Brother', -5.165914074923474e-09), ('ภรรยาของเขา', 4.9249516469403836e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 2 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12 , 2020 .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('11', -5.190822749666012e-09), ('นท', -2.3475847830633787e-09), ('12', -2.341220547561406e-09), ('อว', -2.3026387707626902e-09), ('ทางตอนใต', -2.1318767306985813e-09), ('ฐอเมร', -1.965338952273433e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 3 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'Two days of heavy rain , high winds , and numerous tornadoes caused major damage across multiple states .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('ฝนตกหน', 1.4690527684446525e-08), ('างหน', 1.1838489693480623e-08), ('นาโดหลายล', -1.1380190342667764e-08), ('กสร', -9.238325418033572e-09), ('states', -9.130078379690171e-09), ('ฐ', -7.427503961791758e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 4 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'Sadly , Brother Albert Barnett and his wife , Sister Susan Barnett , 85 and 75 years old respectively , were killed when a tornado struck their mobile home .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('were', -1.5241277705014675e-08), ('when', 1.4054316301066879e-08), ('Brother', -9.220822799161447e-09), ('มบ', -8.042452088677718e-09), ('struck', -6.69853220905953e-09), ('ภรรยาของเขา', -6.546856373500485e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 5 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'The United States branch also reports that at least four of our brothers' homes sustained minor damage , along with two Kingdom Halls .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('The', -6.928235021465077e-09), ('four', -5.071216994084436e-09), ('าบ', -4.432967830896423e-09), ('อมก', -4.232161543104857e-09), ('านของบราเดอร', -3.150263066849767e-09), ('at', 3.076680514867252e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 6 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'Additionally , the storms caused major damage to a brother 's business property .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('Additionally', -1.2439928725187752e-08), ('นอกจากน', -6.636375304280142e-09), ('จของบราเดอร', 3.356132293376232e-09), ('างความเส', 2.7879937253163163e-09), ('to', -2.7696949733876353e-09), ('กต', 2.668694757313025e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 7 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('ผ', -3.1315526823673458e-09), ('are', -2.33613591401886e-09), ('by', -2.308389847709204e-09), ('แลภาคกำล', -2.015262092676841e-09), ('บ', -1.883112631471506e-09), ('those', -1.8193213500220773e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 8 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'We know that our heavenly Father , Jehovah , is providing comfort to our brothers and sisters who are grieving because of this tragedy .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('เราร', -4.7995118168464256e-09), ('We', -3.4862006587222655e-09), ('ดาบนสวรรค', -3.1818698508450587e-09), ('providing', 2.6072726160661064e-09), ('are', -2.4018433614400314e-09), ('พระยะโฮวา', -2.0913350460722445e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 9 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'International government agencies and officials have responded to Russia 's Supreme Court decision that criminalizes the worship of Jehovah 's Witnesses in Russia .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('decision', -3.2014751213721923e-09), ('วยงานร', -3.164850234714558e-09), ('างประเทศและเจ', -2.8643337867162418e-09), ('หน', -2.030721277986848e-09), ('that', -1.8602313934959648e-09), ('s', 1.5595094341127537e-09)]\n",
            "\n",
            "\n",
            "--- GIẢI THÍCH CHO CÂU 10 ---\n",
            "Đang phân tích các từ nguồn ảnh hưởng đến điểm BLEU so với câu tham khảo: 'These statements have criticized Russia 's unjust and harsh judicial action against a minority religious group known for peaceful religious activity .'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation: [('These', -1.071552542889616e-08), ('นการทางกฎหมายท', -3.2609704978947955e-09), ('have', -2.3760834263332615e-09), ('จกรรมทางศาสนาอย', -2.2072951349011548e-09), ('าน', -2.1120428582240097e-09), ('known', -1.595341121168384e-09)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **III - Mô hình với tăng cường dữ liệu**"
      ],
      "metadata": {
        "id": "Ml53DbOIQQp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 1: Xử lí dữ liệu**"
      ],
      "metadata": {
        "id": "gOWzzc3L9atH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Bỏ dấu ngoặc, ký hiệu đặc biệt (giữ lại dấu chấm, dấu hỏi, dấu phẩy, chữ)\n",
        "    text = re.sub(r'[\\(\\)\\[\\]\\{\\}\"\\':=]', '', text)\n",
        "\n",
        "    # Bỏ biểu cảm kiểu =))), :))), :D\n",
        "    text = re.sub(r'[=:;][)D]+', '', text)\n",
        "\n",
        "    # Bỏ dấu ? nếu đứng sau biểu cảm\n",
        "    text = re.sub(r'[\\)=]+[\\?]+', '', text)\n",
        "\n",
        "    # Rút gọn nhiều dấu ? về 1 dấu ?\n",
        "    text = re.sub(r'\\?{2,}', '?', text)\n",
        "\n",
        "    # Rút gọn nhiều dấu chấm (...) về 1 chấm\n",
        "    text = re.sub(r'\\.{2,}', '.', text)\n",
        "\n",
        "    # Bỏ các tag HTML, markdown nếu có\n",
        "    text = re.sub(r'<[^>]+>', '', text)\n",
        "    text = re.sub(r'\\*+', '', text)\n",
        "\n",
        "    # Chuẩn hóa khoảng trắng\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text if re.search(r'\\w', text) else None\n",
        "input_path = \"../data_augment/train.en\"\n",
        "output_path = \"\"\n",
        "\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    for line in infile:\n",
        "        cleaned = clean_text(line)\n",
        "        if cleaned:\n",
        "            outfile.write(cleaned + \"\\n\")\n"
      ],
      "metadata": {
        "id": "2hu2k0P29aHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 2: Sử dụng GG Translator để dịch ngược**"
      ],
      "metadata": {
        "id": "Rec3AiBO--eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "import os\n",
        "import yaml\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool, cpu_count, Manager, Lock\n",
        "import sys\n",
        "sys.stdout.reconfigure(encoding='utf-8')\n",
        "\n",
        "CACHE_FILE = \"data_augment/cache_translate.txt\"\n",
        "NUM_PROCESSES = 12\n",
        "\n",
        "def load_cache():\n",
        "    if not os.path.exists(CACHE_FILE):\n",
        "        return {}\n",
        "    with open(CACHE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [line.strip().split(\"|||\") for line in f if \"|||\" in line]\n",
        "    return {src: tgt for src, tgt in lines}\n",
        "\n",
        "def update_cache(cache):\n",
        "    with open(CACHE_FILE, \"a\", encoding=\"utf-8\") as f:\n",
        "        for src, tgt in cache.items():\n",
        "            f.write(f\"{src}|||{tgt}\\n\")\n",
        "\n",
        "def translate_line(args):\n",
        "    line, src_lang, dest_lang, cache_shared, output_path, lock = args\n",
        "\n",
        "    if line in cache_shared:\n",
        "        translated = cache_shared[line]\n",
        "    else:\n",
        "        try:\n",
        "            translated = GoogleTranslator(source=src_lang, target=dest_lang).translate(line)\n",
        "            # Kiểm tra nếu không đổi thì đánh dấu là lỗi\n",
        "            if translated.strip() == line.strip():\n",
        "                print(f\" Không dịch được: {line}\")\n",
        "        except Exception:\n",
        "            translated = line\n",
        "        cache_shared[line] = translated\n",
        "\n",
        "        with lock:\n",
        "            with open(output_path, \"a\", encoding=\"utf-8\") as f_out:\n",
        "                f_out.write(translated + \"\\n\")\n",
        "\n",
        "    return line, translated\n",
        "\n",
        "def run_translation_block(config_block, shared_cache):\n",
        "    src_lang = config_block[\"src_lang\"]\n",
        "    dest_lang = config_block[\"dest_lang\"]\n",
        "    input_file = config_block[\"input_data\"]\n",
        "    output_file = config_block[\"output_data\"]\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "\n",
        "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    already_done = 0\n",
        "    if os.path.exists(output_file):\n",
        "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            already_done = len([line for line in f if line.strip()])\n",
        "        print(f\"Tiếp tục từ dòng {already_done}/{len(lines)}\")\n",
        "\n",
        "    lines = lines[already_done:]\n",
        "\n",
        "    if not lines:\n",
        "        print(f\" Đã dịch xong: {output_file}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nBắt đầu dịch: {src_lang} → {dest_lang} ({len(lines)} dòng)\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    manager = Manager()\n",
        "    lock = manager.Lock()\n",
        "\n",
        "    args = [(line, src_lang, dest_lang, shared_cache, output_file, lock) for line in lines]\n",
        "\n",
        "    with Pool(processes=min(cpu_count(), NUM_PROCESSES)) as pool:\n",
        "        results = list(tqdm(pool.imap(translate_line, args), total=len(args)))\n",
        "\n",
        "    update_cache(dict(results))\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f \"Dịch xong: {output_file} ({int(elapsed_time // 60)} phút {int(elapsed_time % 60)} giây)\")\n",
        "\n",
        "def run_backtranslation(config_path):\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = yaml.safe_load(f)[\"back_translation\"]\n",
        "\n",
        "    manager = Manager()\n",
        "    shared_cache = manager.dict(load_cache())\n",
        "\n",
        "    start = time.time()\n",
        "    # run_translation_block(config[\"vi_to_en\"], shared_cache)\n",
        "    run_translation_block(config[\"en_to_vi\"], shared_cache)\n",
        "    print(f\"\\nTổng thời gian: {int((time.time() - start) // 60)} phút\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_backtranslation(\"../model/data_augment/config/config.yaml\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kvlyLa12_J7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 3: Xây dựng bảng cắt tỉa cụm từ**"
      ],
      "metadata": {
        "id": "nBovnTCO_i6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/clab/fast_align.git\n",
        "%cd fast_align\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake ..\n",
        "!make\n"
      ],
      "metadata": {
        "id": "n7kekKjK_nt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đường dẫn file\n",
        "en_file = \"../data_augment/train.en\"\n",
        "vi_file = \"../data_augment/train.vi\"\n",
        "output_file = \"../data_augment/aligned.txt\"\n",
        "\n",
        "# Đọc dữ liệu\n",
        "with open(en_file, \"r\", encoding=\"utf-8\") as f_en, \\\n",
        "     open(vi_file, \"r\", encoding=\"utf-8\") as f_vi:\n",
        "\n",
        "    en_lines = [line.strip() for line in f_en]\n",
        "    vi_lines = [line.strip() for line in f_vi]\n",
        "\n",
        "# Kiểm tra độ dài\n",
        "assert len(vi_lines) == len(en_lines)\n",
        "\n",
        "# Gộp và ghi ra file\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
        "    for en, vi in zip(en_lines, vi_lines):\n",
        "        f_out.write(f\"{en} ||| {vi}\\n\")\n",
        "\n",
        "print(f\"Đã tạo file {output_file} với {len(en_lines)} dòng.\")\n"
      ],
      "metadata": {
        "id": "7jdmpx-9_zSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./fast_align -i ../data_augment/aligned.txt -d -o -v > ../data_augment/forward.align"
      ],
      "metadata": {
        "id": "QEm5mhSp_19d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import json\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "EN_STOPWORDS = {\n",
        "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\",\n",
        "    \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
        "    \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\",\n",
        "    \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\",\n",
        "    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\",\n",
        "    \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
        "    \"have\", \"has\", \"had\", \"having\",\n",
        "    \"do\", \"does\", \"did\", \"doing\",\n",
        "    \"a\", \"an\", \"the\",\n",
        "    \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
        "    \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\n",
        "    \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\",\n",
        "    \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\",\n",
        "    \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\",\n",
        "    \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\",\n",
        "    \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\",\n",
        "    \"so\", \"than\", \"too\", \"very\",\n",
        "    \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"\n",
        "}\n",
        "\n",
        "def clean_phrase(phrase):\n",
        "    return phrase.strip().strip('\"“”‘’`\\'.,:;!?')\n",
        "\n",
        "def load_config(path=\"../model/data_augment/config/config.yaml\"):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return yaml.safe_load(f)[\"pruning\"]\n",
        "\n",
        "def load_alignments(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [line.strip().split() for line in f.readlines()]\n",
        "\n",
        "def extract_phrase_pairs(en_data, vi_data, align_file, output_file, max_ngram=3):\n",
        "    def extract_aligned_phrases(en_words, vi_words, alignments, max_n=3):\n",
        "        phrase_table = []\n",
        "        align_dict = defaultdict(list)\n",
        "        for a in alignments:\n",
        "            try:\n",
        "                e_idx, v_idx = map(int, a.split('-'))\n",
        "                align_dict[e_idx].append(v_idx)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        for e_start in range(len(en_words)):\n",
        "            for e_len in range(1, max_n + 1):\n",
        "                e_end = e_start + e_len\n",
        "                if e_end > len(en_words):\n",
        "                    continue\n",
        "\n",
        "                e_indices = list(range(e_start, e_end))\n",
        "                v_indices = []\n",
        "                for ei in e_indices:\n",
        "                    v_indices.extend(align_dict.get(ei, []))\n",
        "                if not v_indices:\n",
        "                    continue\n",
        "\n",
        "                v_start = min(v_indices)\n",
        "                v_end = max(v_indices) + 1\n",
        "                if v_end > len(vi_words):\n",
        "                    continue\n",
        "\n",
        "                en_phrase = clean_phrase(\" \".join(en_words[e_start:e_end]))\n",
        "                vi_phrase = clean_phrase(\" \".join(vi_words[v_start:v_end]))\n",
        "                if en_phrase and vi_phrase:\n",
        "                    phrase_table.append((en_phrase, vi_phrase))\n",
        "        return phrase_table\n",
        "\n",
        "    with open(en_data, 'r', encoding='utf-8') as f_en, \\\n",
        "         open(vi_data, 'r', encoding='utf-8') as f_vi:\n",
        "        en_lines = [line.strip().split() for line in f_en]\n",
        "        vi_lines = [line.strip().split() for line in f_vi]\n",
        "\n",
        "    alignments = load_alignments(align_file)\n",
        "    phrase_table = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for idx, (en_words, vi_words, align_line) in enumerate(zip(en_lines, vi_lines, alignments)):\n",
        "        phrase_pairs = extract_aligned_phrases(en_words, vi_words, align_line, max_ngram)\n",
        "        for en_phrase, vi_phrase in phrase_pairs:\n",
        "            phrase_table[en_phrase][vi_phrase] += 1\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
        "        for en, vi_dict in phrase_table.items():\n",
        "            for vi, count in vi_dict.items():\n",
        "                f_out.write(f\"{en} ||| {vi} ||| {count}\\n\")\n",
        "\n",
        "    print(f\"Đã trích phrase-pair 1–{max_ngram} từ → {output_file}\")\n",
        "    return phrase_table\n",
        "\n",
        "def prune_and_save_dict(phrase_table, phrase_dict_path, threshold):\n",
        "    phrase_dict = {}\n",
        "    for en_phrase, vi_counter in phrase_table.items():\n",
        "        if en_phrase.lower() in EN_STOPWORDS:\n",
        "            continue\n",
        "\n",
        "        filtered_vi = [(vi, count) for vi, count in vi_counter.items() if count >= threshold]\n",
        "        if filtered_vi:\n",
        "            top_vi = max(filtered_vi, key=lambda x: x[1])[0]\n",
        "            en_clean = clean_phrase(en_phrase)\n",
        "            vi_clean = clean_phrase(top_vi)\n",
        "            if en_clean and vi_clean:\n",
        "                phrase_dict[en_clean] = vi_clean\n",
        "\n",
        "    with open(phrase_dict_path, 'w', encoding='utf-8') as f_out:\n",
        "        json.dump(phrase_dict, f_out, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Đã lưu phrase dictionary → {phrase_dict_path}\")\n",
        "\n",
        "def run_pipeline():\n",
        "    config = load_config()\n",
        "\n",
        "    print(\"Trích cụm từ từ alignments...\")\n",
        "    phrase_table = extract_phrase_pairs(\n",
        "        en_data=config[\"en_data\"],\n",
        "        vi_data=config[\"vi_data\"],\n",
        "        align_file=config[\"align_file\"],\n",
        "        output_file=config[\"phrase_table\"],\n",
        "        max_ngram=config.get(\"max_ngram\", 3)\n",
        "    )\n",
        "\n",
        "    print(\"Cắt tỉa và xuất dictionary...\")\n",
        "    prune_and_save_dict(\n",
        "        phrase_table=phrase_table,\n",
        "        phrase_dict_path=config[\"phrase_dict\"],\n",
        "        threshold=config[\"threshold\"]\n",
        "    )\n",
        "\n",
        "    print(\"Đã xong\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()\n"
      ],
      "metadata": {
        "id": "LZ_EMhEq_744"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 4: Gộp tất cả dữ liệu lại cho việc huấn luyện mô hình Transformer**"
      ],
      "metadata": {
        "id": "EBupAkcwABiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Đảm bảo stdout ghi ra UTF-8\n",
        "sys.stdout.reconfigure(encoding='utf-8')\n",
        "\n",
        "def load_config(config_path):\n",
        "    with open(config_path, 'r', encoding='utf-8') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "def load_phrase_dict(phrase_dict_file):\n",
        "    with open(phrase_dict_file, 'r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def combine_data(raw_en, raw_vi, backtrans_en, backtrans_vi, out_en_file, out_vi_file):\n",
        "    os.makedirs(os.path.dirname(out_en_file), exist_ok=True)\n",
        "\n",
        "    en_lines = []\n",
        "    vi_lines = []\n",
        "\n",
        "    with open(raw_en, 'r', encoding='utf-8') as f:\n",
        "        en_lines.extend([line.strip() for line in f if line.strip()])\n",
        "    with open(raw_vi, 'r', encoding='utf-8') as f:\n",
        "        vi_lines.extend([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    with open(backtrans_en, 'r', encoding='utf-8') as f:\n",
        "        en_lines.extend([line.strip() for line in f if line.strip()])\n",
        "    with open(backtrans_vi, 'r', encoding='utf-8') as f:\n",
        "        vi_lines.extend([line.strip() for line in f if line.strip()])\n",
        "\n",
        "    with open(out_en_file, 'w', encoding='utf-8') as f_en:\n",
        "        for line in en_lines:\n",
        "            f_en.write(line + '\\n')\n",
        "    with open(out_vi_file, 'w', encoding='utf-8') as f_vi:\n",
        "        for line in vi_lines:\n",
        "            f_vi.write(line + '\\n')\n",
        "\n",
        "    return en_lines, vi_lines\n",
        "\n",
        "def augment_from_phrase_dict(phrase_dict, max_samples=10000):\n",
        "    augmented_en = []\n",
        "    augmented_vi = []\n",
        "\n",
        "    items = list(phrase_dict.items())\n",
        "    random.shuffle(items)\n",
        "\n",
        "    for en_phrase, vi_phrase in items[:max_samples]:\n",
        "        en_phrase = en_phrase.strip()\n",
        "        vi_phrase = vi_phrase.strip()\n",
        "        if en_phrase and vi_phrase:\n",
        "            augmented_en.append(en_phrase)\n",
        "            augmented_vi.append(vi_phrase)\n",
        "\n",
        "    return augmented_en, augmented_vi\n",
        "\n",
        "def save_augmented_data(en_lines, vi_lines, out_en_file, out_vi_file):\n",
        "    with open(out_en_file, 'w', encoding='utf-8') as f_en:\n",
        "        for line in en_lines:\n",
        "            f_en.write(line + '\\n')\n",
        "\n",
        "    with open(out_vi_file, 'w', encoding='utf-8') as f_vi:\n",
        "        for line in vi_lines:\n",
        "            f_vi.write(line + '\\n')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config = load_config(\"../model/data_augment/config/config.yaml\")\n",
        "\n",
        "    # Bước 1: Gộp dữ liệu gốc + back-translation\n",
        "    en_lines, vi_lines = combine_data(\n",
        "        config['nmt']['en_data'],\n",
        "        config['nmt']['vi_data'],\n",
        "        config['back_translation']['vi_to_en']['output_data'],\n",
        "        config['back_translation']['en_to_vi']['output_data'],\n",
        "        \"../data_augment/train_combined.en\",\n",
        "        \"../data_augment/train_combined.vi\"\n",
        "    )\n",
        "\n",
        "    # Bước 2: Làm giàu từ phrase_dict\n",
        "    phrase_dict = load_phrase_dict(config['pruning']['phrase_dict'])\n",
        "    aug_en, aug_vi = augment_from_phrase_dict(phrase_dict, max_samples=10000)\n",
        "\n",
        "    # Bước 3: Gộp toàn bộ vào tập huấn luyện mở rộng\n",
        "    total_en = en_lines + aug_en\n",
        "    total_vi = vi_lines + aug_vi\n",
        "\n",
        "    save_augmented_data(\n",
        "        total_en,\n",
        "        total_vi,\n",
        "        \"../data_augment/train_augmented.en\",\n",
        "        \"../data_augment/train_augmented.vi\"\n",
        "    )\n",
        "\n",
        "    print(f\"Đã lưu train_augmented.en & train_augmented.vi ({len(total_en)} cặp)\")\n"
      ],
      "metadata": {
        "id": "fMNYo3EfAJRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bước 5: Xây dựng mô hình Transformer và tiến hành huấn luyện, đánh giá**"
      ],
      "metadata": {
        "id": "Vopni0vaHK0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "class NMTModel(nn.Module):\n",
        "    def __init__(self, model_name=\"Helsinki-NLP/opus-mt-en-vi\"):\n",
        "        super(NMTModel, self).__init__()\n",
        "        self.tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "        self.model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "    def forward(self, src_ids, src_mask, tgt_ids, tgt_mask):\n",
        "        outputs = self.model(input_ids=src_ids, attention_mask=src_mask, decoder_input_ids=tgt_ids, decoder_attention_mask=tgt_mask)\n",
        "        return outputs.logits\n",
        "\n",
        "    def translate(self, text, max_length=128):\n",
        "        self.model.eval()\n",
        "        device = next(self.model.parameters()).device\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_length=max_length,\n",
        "                num_beams=4,\n",
        "                early_stopping=True,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "                pad_token_id=self.tokenizer.pad_token_id\n",
        "            )\n",
        "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "DX4dj-ycAavw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  import yaml\n",
        "  import os\n",
        "  import torch\n",
        "  from torch.utils.data import Dataset, DataLoader, random_split\n",
        "  from transformers import MarianMTModel, MarianTokenizer\n",
        "  from tqdm import tqdm\n",
        "  import sacrebleu\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "  # Dataset NMT\n",
        "  class MarianDataset(Dataset):\n",
        "      def __init__(self, src_path, tgt_path, tokenizer, max_length=128):\n",
        "          self.src_lines = self._load_file(src_path)\n",
        "          self.tgt_lines = self._load_file(tgt_path)\n",
        "          assert len(self.src_lines) == len(self.tgt_lines), \"[!] Số dòng không khớp giữa EN và VI\"\n",
        "          self.tokenizer = tokenizer\n",
        "          self.max_length = max_length\n",
        "\n",
        "      def _load_file(self, path):\n",
        "          with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "              return [line.strip() for line in f if line.strip()]\n",
        "\n",
        "      def __len__(self):\n",
        "          return len(self.src_lines)\n",
        "\n",
        "      def __getitem__(self, idx):\n",
        "          src = self.src_lines[idx]\n",
        "          tgt = self.tgt_lines[idx]\n",
        "\n",
        "          inputs = self.tokenizer(\n",
        "              src,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              max_length=self.max_length,\n",
        "              return_tensors=\"pt\"\n",
        "          )\n",
        "          labels = self.tokenizer(\n",
        "              tgt,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              max_length=self.max_length,\n",
        "              return_tensors=\"pt\"\n",
        "          ).input_ids\n",
        "\n",
        "          return {\n",
        "              \"input_ids\": inputs.input_ids.squeeze(),\n",
        "              \"attention_mask\": inputs.attention_mask.squeeze(),\n",
        "              \"labels\": labels.squeeze()\n",
        "          }\n",
        "\n",
        "  # Config\n",
        "  def load_config(config_path):\n",
        "      with open(config_path, 'r', encoding='utf-8') as f:\n",
        "          return yaml.safe_load(f)\n",
        "\n",
        "\n",
        "  # Checkpoint\n",
        "  def save_checkpoint(model, optimizer, epoch, model_dir):\n",
        "      path = os.path.join(model_dir, \"checkpoint_last.pt\")\n",
        "      torch.save({\n",
        "          'epoch': epoch,\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict()\n",
        "      }, path)\n",
        "\n",
        "  def load_checkpoint(model, optimizer, model_dir, device):\n",
        "      path = os.path.join(model_dir, \"checkpoint_last.pt\")\n",
        "      if os.path.isfile(path):\n",
        "          checkpoint = torch.load(path, map_location=device)\n",
        "          model.load_state_dict(checkpoint['model_state_dict'])\n",
        "          optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "          print(f\"Resumed from checkpoint at epoch {checkpoint['epoch']}\")\n",
        "          return checkpoint['epoch'] + 1\n",
        "      return 0\n",
        "\n",
        "\n",
        "  # Evaluate BLEU\n",
        "  def evaluate_bleu(model, tokenizer, dataloader, device, max_batches=20):\n",
        "      model.eval()\n",
        "      refs, hyps = [], []\n",
        "      with torch.no_grad():\n",
        "          for i, batch in enumerate(dataloader):\n",
        "              if i >= max_batches:\n",
        "                  break\n",
        "              input_ids = batch[\"input_ids\"].to(device)\n",
        "              attention_mask = batch[\"attention_mask\"].to(device)\n",
        "              labels = batch[\"labels\"]\n",
        "\n",
        "              outputs = model.generate(\n",
        "                  input_ids=input_ids,\n",
        "                  attention_mask=attention_mask,\n",
        "                  max_length=128,\n",
        "                  num_beams=1\n",
        "              )\n",
        "              decoded_preds = [tokenizer.decode(g, skip_special_tokens=True) for g in outputs]\n",
        "              decoded_labels = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
        "\n",
        "              hyps.extend(decoded_preds)\n",
        "              refs.extend(decoded_labels)\n",
        "\n",
        "      bleu = sacrebleu.corpus_bleu(hyps, [refs]).score\n",
        "      model.train()\n",
        "      return bleu\n",
        "\n",
        "  # Plot Loss & BLEU\n",
        "  def plot_metrics(log_path=\"logs/train.log\", save_path=\"logs/metrics.png\"):\n",
        "      epochs, losses, bleus = [], [], []\n",
        "      with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "          for line in f:\n",
        "              parts = line.strip().split(\",\")\n",
        "              epoch = int(parts[0].split()[1])\n",
        "              loss = float(parts[1].split(\":\")[1])\n",
        "              bleu = float(parts[2].split(\":\")[1])\n",
        "              epochs.append(epoch)\n",
        "              losses.append(loss)\n",
        "              bleus.append(bleu)\n",
        "\n",
        "      plt.figure(figsize=(10,5))\n",
        "\n",
        "      plt.subplot(1,2,1)\n",
        "      plt.plot(epochs, losses, marker='o', color='red')\n",
        "      plt.title(\"Training Loss\")\n",
        "      plt.xlabel(\"Epoch\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "\n",
        "      plt.subplot(1,2,2)\n",
        "    plt.plot(epochs, bleus, marker='o', color='blue')\n",
        "    plt.title(\"Validation BLEU\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"BLEU\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    print(f\"Saved training curves to {save_path}\")\n",
        "\n",
        "# Train NMT\n",
        "def train_nmt(config_path):\n",
        "    config = load_config(config_path)['nmt']\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    tokenizer = MarianTokenizer.from_pretrained(config['model_name'])\n",
        "    model = MarianMTModel.from_pretrained(config['model_name']).to(device)\n",
        "\n",
        "    dataset = MarianDataset(\n",
        "        src_path=config['train_en'],\n",
        "        tgt_path=config['train_vi'],\n",
        "        tokenizer=tokenizer,\n",
        "        max_length=config.get('max_len', 128)\n",
        "    )\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = min(200, int(0.1 * len(dataset)))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=config['batch_size'])\n",
        "    test_loader = DataLoader(test_set, batch_size=config['batch_size'])\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=float(config['learning_rate']))\n",
        "\n",
        "    os.makedirs(config['model_dir'], exist_ok=True)\n",
        "    os.makedirs(\"logs\", exist_ok=True)\n",
        "\n",
        "    start_epoch = load_checkpoint(model, optimizer, config['model_dir'], device)\n",
        "\n",
        "    print(f\"Training on {device} (starting from epoch {start_epoch})\")\n",
        "    for epoch in range(start_epoch, config['epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
        "        for batch in progress_bar:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "        val_bleu = evaluate_bleu(model, tokenizer, val_loader, device, max_batches=20)\n",
        "\n",
        "        torch.save(model.state_dict(), os.path.join(config['model_dir'], f\"nmt_epoch_{epoch}.pt\"))\n",
        "        save_checkpoint(model, optimizer, epoch, config['model_dir'])\n",
        "\n",
        "        with open(\"logs/train.log\", 'a', encoding='utf-8') as f:\n",
        "            f.write(f\"Epoch {epoch}, Loss:{avg_loss:.4f}, ValBLEU:{val_bleu:.2f}\\n\")\n",
        "\n",
        "        print(f\"Epoch {epoch} — Avg Loss: {avg_loss:.4f}, Val BLEU: {val_bleu:.2f}\")\n",
        "\n",
        "    test_bleu = evaluate_bleu(model, tokenizer, test_loader, device, max_batches=50)\n",
        "    print(f\"\\nFinal Test BLEU: {test_bleu:.2f}\")\n",
        "\n",
        "    plot_metrics(\"../data_augment/logs/train.log\", \"../data_augment/metrics.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_nmt(\"../model/data_augment/config/config.yaml\")\n"
      ],
      "metadata": {
        "id": "Hdpl6FEf9xPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IV - Các hàm đánh giá và xử lý chung**"
      ],
      "metadata": {
        "id": "IL3g-gLI493u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 - Xây dựng mô hình sửa lỗi ngữ pháp và teencode**"
      ],
      "metadata": {
        "id": "9UubGMMs94-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "\n",
        "# === Cấu hình ===\n",
        "PRETRAINED_MODEL = \"VietAI/vit5-base\"\n",
        "CHECKPOINT_DIR = \"../model/data_augment/checkpoints/gec\"\n",
        "LOG_DIR = \"../model/data_augment/gec\"\n",
        "SRC_PATH = \"../data_augment/train.src\"\n",
        "TGT_PATH = \"../data_augment/train.tgt\"\n",
        "\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# === Tải dữ liệu gốc ===\n",
        "with open(SRC_PATH, encoding=\"utf-8\") as f:\n",
        "    src_lines = [line.strip() for line in f if line.strip()]\n",
        "with open(TGT_PATH, encoding=\"utf-8\") as f:\n",
        "    tgt_lines = [line.strip() for line in f if line.strip()]\n",
        "assert len(src_lines) == len(tgt_lines), \"Số dòng không khớp!\"\n",
        "\n",
        "# === Chia train/val ===\n",
        "train_src, val_src, train_tgt, val_tgt = train_test_split(\n",
        "    src_lines, tgt_lines, test_size=0.05, random_state=42\n",
        ")\n",
        "train_data = Dataset.from_dict({\"input\": train_src, \"target\": train_tgt})\n",
        "val_data = Dataset.from_dict({\"input\": val_src, \"target\": val_tgt})\n",
        "\n",
        "# === Kiểm tra checkpoint gần nhất ===\n",
        "last_ckpt = get_last_checkpoint(CHECKPOINT_DIR)\n",
        "if last_ckpt:\n",
        "    print(f\"Đang tiếp tục huấn luyện từ checkpoint: {last_ckpt}\")\n",
        "    # Xoá file rng_state.pth để tránh lỗi UnpicklingError (PyTorch 2.6+)\n",
        "    rng_file = os.path.join(last_ckpt, \"rng_state.pth\")\n",
        "    if os.path.exists(rng_file):\n",
        "        os.remove(rng_file)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(last_ckpt)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(last_ckpt)\n",
        "else:\n",
        "    print(\"Bắt đầu huấn luyện mới từ mô hình gốc...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(PRETRAINED_MODEL)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(\"Thiết bị:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "\n",
        "# === Tiền xử lý dữ liệu ===\n",
        "max_len = 128\n",
        "def preprocess(example):\n",
        "    inputs = tokenizer(\"gec: \" + example[\"input\"], truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "    targets = tokenizer(example[\"target\"], truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_train = train_data.map(preprocess, batched=False)\n",
        "tokenized_val = val_data.map(preprocess, batched=False)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# === Cấu hình huấn luyện ===\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=CHECKPOINT_DIR,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=5,\n",
        "    logging_dir=LOG_DIR,\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    optim=\"adafactor\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    overwrite_output_dir=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# === Huấn luyện ===\n",
        "if __name__ == \"__main__\":\n",
        "    trainer.train(resume_from_checkpoint=last_ckpt if last_ckpt else None)\n",
        "    model.save_pretrained(CHECKPOINT_DIR)\n",
        "    tokenizer.save_pretrained(CHECKPOINT_DIR)\n",
        "    print(f\"Đã lưu mô hình vào: {CHECKPOINT_DIR}\")\n"
      ],
      "metadata": {
        "id": "8rEy_R3M9_Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 - Sử dụng mô hình sửa lỗi ngữ pháp để xử lý dữ liệu đầu vào**"
      ],
      "metadata": {
        "id": "05LMWA9E-VAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Cấu hình ===\n",
        "CHECKPOINT_DIR = \"../model/data_augment/checkpoints/gec/checkpoint-16238\"\n",
        "INPUT_FILE = \"../data_augment/train.vi\"\n",
        "OUTPUT_FILE = \"../data_augment/train.corrected.vi\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 128\n",
        "MAX_LEN = 128\n",
        "PREFIX = \"gec: \"\n",
        "\n",
        "# === Tải model và tokenizer ===\n",
        "print(\" Đang tải model và tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_DIR)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(CHECKPOINT_DIR)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.half()\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "print(f\"Model loaded on: {DEVICE}\")\n",
        "\n",
        "# === Đọc dữ liệu cần sửa lỗi ===\n",
        "with open(INPUT_FILE, encoding=\"utf-8\") as f:\n",
        "    all_lines = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "# === Nếu đã có kết quả, tiếp tục từ chỗ dừng ===\n",
        "start_idx = 0\n",
        "if os.path.exists(OUTPUT_FILE):\n",
        "    with open(OUTPUT_FILE, encoding=\"utf-8\") as f:\n",
        "        done_lines = sum(1 for _ in f)\n",
        "        start_idx = done_lines\n",
        "        print(f\" Đang tiếp tục từ dòng {start_idx}/{len(all_lines)}\")\n",
        "\n",
        "# === Mở file ghi kết quả ===\n",
        "with open(OUTPUT_FILE, \"a\", encoding=\"utf-8\") as fout:\n",
        "    for i in tqdm(range(start_idx, len(all_lines), BATCH_SIZE), desc=\"Sửa lỗi\"):\n",
        "        batch = all_lines[i:i + BATCH_SIZE]\n",
        "        inputs = tokenizer(\n",
        "            [PREFIX + x for x in batch],\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"longest\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_length=MAX_LEN,\n",
        "                do_sample=False\n",
        "            )\n",
        "\n",
        "        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        fout.write(\"\\n\".join(decoded) + \"\\n\")\n",
        "\n",
        "print(f\"\\n Hoàn tất sửa lỗi. Kết quả lưu tại: {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "id": "F5UEJY3p-FnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 - Đánh giá BLEU Score**"
      ],
      "metadata": {
        "id": "sl9hPWM8QU9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu pandas nltk\n",
        "import sentencepiece as spm\n",
        "import json\n",
        "import gc\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "# Hàm đánh giá (sửa để không dùng generate)\n",
        "def evaluate_model_multisource(model, test_data, model_name):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = test_data[\"vi\"].tolist()\n",
        "    batch_size = 32  # Giảm từ 32 xuống 16 để tiết kiệm VRAM\n",
        "\n",
        "    # Tải từ vựng POS và SentencePiece\n",
        "    drive_path = '/content/drive/My Drive/TieuLuanNLP/multi_source/'\n",
        "    with open(os.path.join('/content/drive/My Drive/TieuLuanNLP/model/multisource_en_vi/', 'pos_vocab.json'), 'r', encoding='utf-8') as f:\n",
        "      pos_vocab = json.load(f)\n",
        "\n",
        "    src_sp = spm.SentencePieceProcessor()\n",
        "    src_sp.load(os.path.join(drive_path, 'src_sp.model'))\n",
        "    tgt_sp = spm.SentencePieceProcessor()\n",
        "    tgt_sp.load(os.path.join(drive_path, 'tgt_sp.model'))\n",
        "\n",
        "    for i in range(0, len(test_data), batch_size):\n",
        "        batch = test_data.iloc[i:i+batch_size]\n",
        "        src_texts = batch[\"en\"].tolist()\n",
        "\n",
        "        # Token hóa và tạo POS tags\n",
        "        src_ids_list, ling_ids_list = [], []\n",
        "        for text in src_texts:\n",
        "            tokens = word_tokenize(text)[:128]\n",
        "            src_ids = [src_sp.piece_to_id(token) for token in tokens]\n",
        "            pos_tags = [pos_vocab.get(tag, 0) for _, tag in pos_tag(tokens)]\n",
        "            src_ids_list.append(src_ids)\n",
        "            ling_ids_list.append(pos_tags)\n",
        "\n",
        "        # Padding\n",
        "        src_ids = torch.tensor([ids + [0] * (128 - len(ids)) if len(ids) < 128 else ids[:128]\n",
        "                               for ids in src_ids_list], dtype=torch.long).to(device)\n",
        "        ling_ids = torch.tensor([ids + [0] * (128 - len(ids)) if len(ids) < 128 else ids[:128]\n",
        "                                for ids in ling_ids_list], dtype=torch.long).to(device)\n",
        "\n",
        "        # Khởi tạo tgt_ids với <s>\n",
        "        tgt_ids = torch.tensor([[tgt_sp.piece_to_id('<s>')] for _ in range(len(src_texts))],\n",
        "                              dtype=torch.long, device=device)\n",
        "\n",
        "        # Suy luận\n",
        "        with torch.no_grad():\n",
        "            for _ in range(50):  # max_length=50\n",
        "                output = model(src_ids, ling_ids, tgt_ids)\n",
        "                next_token = output[:, -1, :].argmax(dim=-1)\n",
        "                tgt_ids = torch.cat((tgt_ids, next_token.unsqueeze(1)), dim=1)\n",
        "                if (next_token == tgt_sp.piece_to_id('</s>')).all():\n",
        "                    break\n",
        "\n",
        "        # Giải mã\n",
        "        batch_predictions = [tgt_sp.decode_ids(tgt.tolist()) for tgt in tgt_ids.cpu()]\n",
        "        predictions.extend(batch_predictions)\n",
        "\n",
        "        # Giải phóng bộ nhớ\n",
        "        del src_ids, ling_ids, tgt_ids, output\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(predictions, [references]).score\n",
        "    print(f\"{model_name} BLEU Score: {bleu}\")\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def evaluate_model(model, test_data, model_name):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = test_data[\"vi\"].tolist()\n",
        "    for i in range(0, len(test_data), 32):\n",
        "        batch = test_data.iloc[i:i+32]\n",
        "        inputs = tokenizer(batch[\"en\"].tolist(), padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs)\n",
        "        predictions.extend(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
        "        del inputs, outputs\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()  # Clear GPU memory\n",
        "        gc.collect()\n",
        "    bleu = sacrebleu.corpus_bleu(predictions, [references]).score\n",
        "    print(f\"{model_name} BLEU Score: {bleu}\")\n",
        "    return predictions\n",
        "from transformers import MarianMTModel\n",
        "\n",
        "# Tải mô hình đã huấn luyện\n",
        "#model_basic = MarianMTModel.from_pretrained(\"/content/drive/My Drive/TieuLuanNLP/model/basic_en_vn\").to(device)\n",
        "model_multi = MultiSourceTransformer.from_pretrained(\"/content/drive/My Drive/TieuLuanNLP/model/multisource_en_vi\").to(device)\n",
        "#model_aug = MarianMTModel.from_pretrained(\"/content/drive/My Drive/TieuLuanNLP/model/data_augment_en_vi/checkpoints/nmt\").to(device)\n",
        "\n",
        "# Đánh giá\n",
        "#preds_basic = evaluate_model(model_basic, test_phomt, \"Transformer cơ bản\")\n",
        "#preds_aug = evaluate_model(model_aug, test_phomt, \"Mô hình tăng cường\")\n",
        "preds_multi = evaluate_model_multisource(model_multi, test_phomt, \"Mô hình đa nguồn\")\n"
      ],
      "metadata": {
        "id": "kdcQmioHQVtp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "a4cdf7e7-f5b7-4f2c-bc5a-b2b783028fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MultiSourceTransformer' object has no attribute 'src_tokenizer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3732769057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m#preds_basic = evaluate_model(model_basic, test_phomt, \"Transformer cơ bản\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m#preds_aug = evaluate_model(model_aug, test_phomt, \"Mô hình tăng cường\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mpreds_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_multi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_phomt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mô hình đa nguồn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3732769057.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_data, model_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4262656472.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mling_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_to_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mpos_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mling_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Cắt ngắn nếu cần\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4262656472.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mling_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_to_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mpos_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mling_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Cắt ngắn nếu cần\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MultiSourceTransformer' object has no attribute 'src_tokenizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer cơ bản BLEU Score: 27.29405794636997\n",
        "\n",
        "Mô hình tăng cường BLEU Score: 23.211848832715262\n",
        "\n",
        "Mô hình đa nguồn BLEU score: 54.73"
      ],
      "metadata": {
        "id": "iSXNzXrKIr2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4 - Sử dụng XAI LIME để giải thích các mô hình**"
      ],
      "metadata": {
        "id": "owok7d72qu0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load mô hình\n",
        "#model =  MarianMTModel.from_pretrained(\"/content/drive/My Drive/TieuLuanNLP/model/basic_en_vn\")\n",
        "model =  MarianMTModel.from_pretrained(\"/content/drive/My Drive/TieuLuanNLP/model/data_augment_en_vi/checkpoints/nmt\")\n",
        "#model = MultiSourceTransformer.from_pretrained(\"/content/drive/My Drive/TieuLuanNLP/model/multisource_en_vi\")\n",
        "\n",
        "# LIME giải thích\n",
        "explainer = LimeTextExplainer(class_names=[\"vi\"])\n",
        "\n",
        "def predict_proba_basic(texts):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    elif not isinstance(texts, list):\n",
        "        raise ValueError(\"Đầu vào cho predict_proba_basic phải là str hoặc list[str]\")\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "    # Tạo decoder_input_ids thủ công (dùng token bắt đầu <s> cho decoder)\n",
        "    decoder_input_ids = torch.ones((inputs[\"input_ids\"].size(0), 1), dtype=torch.long, device=\"cpu\") * tokenizer.convert_tokens_to_ids(\"<s>\")\n",
        "    with torch.no_grad():\n",
        "        # Gọi mô hình với decoder_input_ids rõ ràng, tắt decoder_inputs_embeds\n",
        "        outputs = model(\n",
        "            **inputs,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            use_cache=False,  # Tắt cache để giảm bộ nhớ\n",
        "            output_hidden_states=False,\n",
        "            output_attentions=False\n",
        "        )\n",
        "        logits = outputs.logits  # Logits của các token dự đoán\n",
        "        # Chuyển logits thành xác suất\n",
        "        probs = torch.softmax(logits, dim=-1)  # Shape: [batch_size, seq_len, vocab_size]\n",
        "        probs = probs[:, 0, :]  # Lấy xác suất của token đầu tiên cho mỗi mẫu\n",
        "    # Trả về mảng xác suất (shape: [num_samples, vocab_size])\n",
        "    return probs.cpu().numpy()\n",
        "\n",
        "for i in range(10):\n",
        "    text = test_phomt.iloc[i][\"en\"]\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        print(f\"Lỗi: Dữ liệu tại dòng {i} không hợp lệ: {text}\")\n",
        "        continue\n",
        "    exp = explainer.explain_instance(text, predict_proba_basic, num_features=6, num_samples=500)\n",
        "    #exp = explainer.explain_instance(text, predict_proba_mutisource, num_features=6, num_samples=500)\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Explanation: {exp.as_list()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "Gzb5qNwjqtOR",
        "outputId": "6dca5366-4a57-47a4-b01f-3c3a8249dbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'MarianMTModel' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2370573658.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarianMTModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMarianTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_text\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'MarianMTModel' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1- bảng dịch transformer cơ bản**\n",
        "\n",
        "```\n",
        "Text: brother albert barnett and his wife , sister susan barnett , from the west congregation in tuscaloosa , alabama\n",
        "\n",
        "Explanation: [(np.str_('his'), -2.0996182684032016e-06), (np.str_('susan'), -1.4826946145904694e-06), (np.str_('brother'), 8.91575255720878e-07), (np.str_('barnett'), 7.523639917550182e-07), (np.str_('albert'), 7.229438778146044e-07), (np.str_('alabama'), 6.242862921000612e-07)]\n",
        "\n",
        "Text: severe storms ripped through parts of the southern and midwestern united states on january 11 and 12 , 2020 .\n",
        "\n",
        "Explanation: [(np.str_('ripped'), -1.4482198924350898e-06), (np.str_('storms'), -1.1239242709494548e-06), (np.str_('on'), -9.466474156549832e-07), (np.str_('severe'), -5.531836322864629e-07), (np.str_('2020'), -4.989570001045183e-07), (np.str_('of'), -4.3672736907293595e-07)]\n",
        "\n",
        "Text: two days of heavy rain , high winds , and numerous tornadoes caused major damage across multiple states .\n",
        "\n",
        "Explanation: [(np.str_('rain'), -1.3265755932110205e-06), (np.str_('days'), -5.167963272566775e-07), (np.str_('of'), 3.542482333299923e-07), (np.str_('across'), -3.0864738658966563e-07), (np.str_('major'), 3.07773549879045e-07), (np.str_('caused'), 1.3952172389578821e-07)]\n",
        "\n",
        "Text: sadly , brother albert barnett and his wife , sister susan barnett , 85 and 75 years old respectively , were killed when a tornado struck their mobile home .\n",
        "\n",
        "Explanation: [(np.str_('sadly'), -5.516835676895757e-06), (np.str_('and'), -7.265597596709589e-07), (np.str_('mobile'), 6.022623230916172e-07), (np.str_('his'), -4.2567762722337795e-07), (np.str_('old'), 3.6071062564500606e-07), (np.str_('barnett'), 2.9811577675836506e-07)]\n",
        "\n",
        "Text: the united states branch also reports that at least four of our brothers ' homes sustained minor damage , along with two kingdom halls .\n",
        "\n",
        "Explanation: [(np.str_('branch'), -5.933460915984073e-07), (np.str_('states'), -3.4537900879159076e-07), (np.str_('damage'), -2.7224922392537005e-07), (np.str_('sustained'), -2.1991929394524682e-07), (np.str_('united'), 1.398518223856316e-07), (np.str_('minor'), 1.2390038876121556e-07)]\n",
        "\n",
        "Text: additionally , the storms caused major damage to a brother 's business property .\n",
        "\n",
        "Explanation: [(np.str_('storms'), 2.204062891933905e-06), (np.str_('caused'), 1.3290147107268105e-06), (np.str_('property'), -1.2296395244240085e-06), (np.str_('major'), 8.47281350361927e-07), (np.str_('additionally'), 8.142361750747797e-07), (np.str_('the'), 5.82157035706973e-07)]\n",
        "\n",
        "Text: local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster .\n",
        "\n",
        "Explanation: [(np.str_('the'), -1.1127893285469542e-06), (np.str_('affected'), -8.56214137031255e-07), (np.str_('elders'), 6.003230312436369e-07), (np.str_('are'), -4.897385120279575e-07), (np.str_('disaster'), -4.518079582280951e-07), (np.str_('those'), 3.692731344800294e-07)]\n",
        "\n",
        "Text: we know that our heavenly father , jehovah , is providing comfort to our brothers and sisters who are grieving because of this tragedy .\n",
        "\n",
        "Explanation: [(np.str_('we'), -2.2797552963155086e-06), (np.str_('jehovah'), 1.8767449909779077e-06), (np.str_('heavenly'), 1.7188782326562614e-06), (np.str_('father'), -1.1991664092050441e-06), (np.str_('that'), -1.1012362201245365e-06), (np.str_('our'), -1.0849781962230887e-06)]\n",
        "\n",
        "Text: international government agencies and officials have responded to russia 's supreme court decision that criminalizes the worship of jehovah 's witnesses in russia .\n",
        "\n",
        "Explanation: [(np.str_('international'), 2.106508942119281e-06), (np.str_('agencies'), -1.484781134968309e-06), (np.str_('officials'), -5.026655486406757e-07), (np.str_('have'), -3.5857592535213093e-07), (np.str_('criminalizes'), -3.36121967682946e-07), (np.str_('russia'), -3.239006792986295e-07)]\n",
        "\n",
        "Text: these statements have criticized russia 's unjust and harsh judicial action against a minority religious group known for peaceful religious activity .\n",
        "\n",
        "Explanation: [(np.str_('have'), -1.742298488112012e-06), (np.str_('statements'), -1.3635646063897632e-06), (np.str_('against'), -1.07635960249973e-06), (np.str_('religious'), 1.000110544649922e-06), (np.str_('known'), 6.708483954050872e-07), (np.str_('action'), -4.914444016665408e-07)]\n",
        "```\n",
        "**2 - Bảng dịch với mô hình đa nguồn**\n",
        "\n",
        "\n",
        "```\n",
        "'Brother Albert Barnett and his wife , Sister Susan Barnett , from the West Congregation in Tuscaloosa , Alabama'\n",
        "\n",
        "Explanation: [('Sister', -9.458128371254788e-09), ('บาร', -6.983643577817748e-09), ('Alabama', 6.586893231817712e-09), ('กรเวสต', -6.581261933728665e-09), ('Brother', -5.165914074923474e-09), ('ภรรยาของเขา', 4.9249516469403836e-09)]\n",
        "\n",
        "\n",
        "'Severe storms ripped through parts of the southern and midwestern United States on January 11 and 12 , 2020 .'\n",
        "\n",
        "Explanation: [('11', -5.190822749666012e-09), ('นท', -2.3475847830633787e-09), ('12', -2.341220547561406e-09), ('อว', -2.3026387707626902e-09), ('ทางตอนใต', -2.1318767306985813e-09), ('ฐอเมร', -1.965338952273433e-09)]\n",
        "\n",
        "\n",
        "'Two days of heavy rain , high winds , and numerous tornadoes caused major damage across multiple states .'\n",
        "\n",
        "Explanation: [('ฝนตกหน', 1.4690527684446525e-08), ('างหน', 1.1838489693480623e-08), ('นาโดหลายล', -1.1380190342667764e-08), ('กสร', -9.238325418033572e-09), ('states', -9.130078379690171e-09), ('ฐ', -7.427503961791758e-09)]\n",
        "\n",
        "\n",
        "'Sadly , Brother Albert Barnett and his wife , Sister Susan Barnett , 85 and 75 years old respectively , were killed when a tornado struck their mobile home .'\n",
        "\n",
        "Explanation: [('were', -1.5241277705014675e-08), ('when', 1.4054316301066879e-08), ('Brother', -9.220822799161447e-09), ('มบ', -8.042452088677718e-09), ('struck', -6.69853220905953e-09), ('ภรรยาของเขา', -6.546856373500485e-09)]\n",
        "\n",
        "\n",
        "'The United States branch also reports that at least four of our brothers' homes sustained minor damage , along with two Kingdom Halls .'\n",
        "\n",
        "Explanation: [('The', -6.928235021465077e-09), ('four', -5.071216994084436e-09), ('าบ', -4.432967830896423e-09), ('อมก', -4.232161543104857e-09), ('านของบราเดอร', -3.150263066849767e-09), ('at', 3.076680514867252e-09)]\n",
        "\n",
        "\n",
        "'Additionally , the storms caused major damage to a brother 's business property .'\n",
        "\n",
        "Explanation: [('Additionally', -1.2439928725187752e-08), ('นอกจากน', -6.636375304280142e-09), ('จของบราเดอร', 3.356132293376232e-09), ('างความเส', 2.7879937253163163e-09), ('to', -2.7696949733876353e-09), ('กต', 2.668694757313025e-09)]\n",
        "\n",
        "\n",
        "'Local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster .'\n",
        "\n",
        "Explanation: [('ผ', -3.1315526823673458e-09), ('are', -2.33613591401886e-09), ('by', -2.308389847709204e-09), ('แลภาคกำล', -2.015262092676841e-09), ('บ', -1.883112631471506e-09), ('those', -1.8193213500220773e-09)]\n",
        "\n",
        "\n",
        "'We know that our heavenly Father , Jehovah , is providing comfort to our brothers and sisters who are grieving because of this tragedy .'\n",
        "\n",
        "Explanation: [('เราร', -4.7995118168464256e-09), ('We', -3.4862006587222655e-09), ('ดาบนสวรรค', -3.1818698508450587e-09), ('providing', 2.6072726160661064e-09), ('are', -2.4018433614400314e-09), ('พระยะโฮวา', -2.0913350460722445e-09)]\n",
        "\n",
        "\n",
        "'International government agencies and officials have responded to Russia 's Supreme Court decision that criminalizes the worship of Jehovah 's Witnesses in Russia .'\n",
        "\n",
        "Explanation: [('decision', -3.2014751213721923e-09), ('วยงานร', -3.164850234714558e-09), ('างประเทศและเจ', -2.8643337867162418e-09), ('หน', -2.030721277986848e-09), ('that', -1.8602313934959648e-09), ('s', 1.5595094341127537e-09)]\n",
        "\n",
        "\n",
        "'These statements have criticized Russia 's unjust and harsh judicial action against a minority religious group known for peaceful religious activity .'\n",
        "\n",
        "Explanation: [('These', -1.071552542889616e-08), ('นการทางกฎหมายท', -3.2609704978947955e-09), ('have', -2.3760834263332615e-09), ('จกรรมทางศาสนาอย', -2.2072951349011548e-09), ('าน', -2.1120428582240097e-09), ('known', -1.595341121168384e-09)]\n",
        "\n",
        "```\n",
        "**3- bảng dịch mô hình với tăng cường dữ liệu**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Text: brother albert barnett and his wife , sister susan barnett , from the west congregation in tuscaloosa , alabama\n",
        "Explanation: [(np.str_('barnett'), -1.3103550077611215e-06), (np.str_('albert'), 5.469086526697135e-07), (np.str_('alabama'), 4.5520018796542316e-07), (np.str_('west'), 4.4683578730688826e-07), (np.str_('and'), 4.322644132458623e-07), (np.str_('wife'), -3.88384079256479e-07)]\n",
        "\n",
        "Text: severe storms ripped through parts of the southern and midwestern united states on january 11 and 12 , 2020 .\n",
        "Explanation: [(np.str_('ripped'), -8.868815222356579e-07), (np.str_('2020'), 6.488173749100982e-07), (np.str_('storms'), -4.00397595392644e-07), (np.str_('united'), -3.567413575908317e-07), (np.str_('through'), -3.0474432974280877e-07), (np.str_('11'), -2.847094985820839e-07)]\n",
        "\n",
        "Text: two days of heavy rain , high winds , and numerous tornadoes caused major damage across multiple states .\n",
        "Explanation: [(np.str_('rain'), -5.601602716887243e-07), (np.str_('tornadoes'), -3.3959246754658786e-07), (np.str_('two'), 3.215680273885648e-07), (np.str_('winds'), -3.062746427130424e-07), (np.str_('states'), -3.012394109016833e-07), (np.str_('and'), -2.0028454865215795e-07)]\n",
        "\n",
        "Text: sadly , brother albert barnett and his wife , sister susan barnett , 85 and 75 years old respectively , were killed when a tornado struck their mobile home .\n",
        "Explanation: [(np.str_('barnett'), -8.857721805859132e-07), (np.str_('brother'), -6.581881418682591e-07), (np.str_('and'), -6.343994998729984e-07), (np.str_('sadly'), -4.654398700272274e-07), (np.str_('respectively'), 4.21378937110256e-07), (np.str_('85'), 3.700906918938194e-07)]\n",
        "\n",
        "Text: the united states branch also reports that at least four of our brothers ' homes sustained minor damage , along with two kingdom halls .\n",
        "Explanation: [(np.str_('united'), -1.7571744865956402e-06), (np.str_('reports'), 1.7421208953549942e-06), (np.str_('our'), -1.511480569437083e-06), (np.str_('also'), -8.769838676639941e-07), (np.str_('minor'), -6.293829626347243e-07), (np.str_('states'), 5.348122244476235e-07)]\n",
        "\n",
        "Text: additionally , the storms caused major damage to a brother 's business property .\n",
        "Explanation: [(np.str_('brother'), -2.5373636971506774e-06), (np.str_('additionally'), -1.219839073024932e-06), (np.str_('business'), -4.642567523436242e-07), (np.str_('damage'), 3.3476036495261816e-07), (np.str_('major'), 2.4639217798821093e-07), (np.str_('s'), -1.3962044056946802e-07)]\n",
        "\n",
        "Text: local elders and the circuit overseer are offering practical and spiritual support to those affected by this disaster .\n",
        "Explanation: [(np.str_('local'), -6.048193064485463e-07), (np.str_('affected'), -5.542455448828236e-07), (np.str_('elders'), 4.855095122660242e-07), (np.str_('practical'), -3.3345427145339693e-07), (np.str_('disaster'), -3.332421241018685e-07), (np.str_('spiritual'), -2.3624210721300785e-07)]\n",
        "\n",
        "Text: we know that our heavenly father , jehovah , is providing comfort to our brothers and sisters who are grieving because of this tragedy .\n",
        "Explanation: [(np.str_('our'), -5.653883645200948e-07), (np.str_('we'), -2.3927145353669736e-07), (np.str_('brothers'), -1.6097107756701561e-07), (np.str_('sisters'), -1.5712924930123118e-07), (np.str_('know'), -1.2203769919555944e-07), (np.str_('providing'), 1.1717898556779603e-07)]\n",
        "\n",
        "Text: international government agencies and officials have responded to russia 's supreme court decision that criminalizes the worship of jehovah 's witnesses in russia .\n",
        "Explanation: [(np.str_('russia'), -2.654086994297247e-07), (np.str_('responded'), -2.421786646846226e-07), (np.str_('jehovah'), -1.8693937657856002e-07), (np.str_('worship'), -1.6976599449322918e-07), (np.str_('international'), -1.419870218950119e-07), (np.str_('witnesses'), -1.3835899703034013e-07)]\n",
        "\n",
        "Text: these statements have criticized russia 's unjust and harsh judicial action against a minority religious group known for peaceful religious activity .\n",
        "Explanation: [(np.str_('these'), 1.5916717223585013e-06), (np.str_('statements'), 5.306968746908933e-07), (np.str_('judicial'), 4.1164408197634823e-07), (np.str_('russia'), -3.361183415083695e-07), (np.str_('unjust'), -3.3371925571982056e-07), (np.str_('harsh'), -3.254668421905307e-07)]\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "PzeRyfnDQV6B"
      }
    }
  ]
}